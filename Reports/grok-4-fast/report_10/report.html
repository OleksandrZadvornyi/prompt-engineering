<html>
  <head>
    <meta charset="utf-8" />
    <title>LLM Code Generation Report #10</title>
    <style>
      body {
        font-family: "Arial", sans-serif;
        line-height: 1.6;
        color: #333;
        margin: 20px auto;
        padding: 20px;
        background-color: #f9f9f9;
      }
      .container {
        background-color: #fff;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }
      h1,
      h2 {
        color: #2c3e50;
        border-bottom: 2px solid #e0e0e0;
        padding-bottom: 8px;
        margin-bottom: 16px;
      }
      h1 {
        font-size: 24px;
      }
      h2 {
        font-size: 20px;
      }
      .header-info p {
        margin: 8px 0;
        font-size: 14px;
      }
      pre {
        background-color: #f4f4f4;
        padding: 12px;
        border-radius: 4px;
        font-size: 13px;
        overflow-x: auto;
      }
      .metrics table {
        width: 100%;
        border-collapse: collapse;
        margin-bottom: 20px;
      }
      .metrics th,
      .metrics td {
        padding: 10px;
        text-align: left;
        border-bottom: 1px solid #e0e0e0;
        font-size: 14px;
      }
      .metrics th {
        background-color: #f0f0f0;
        font-weight: bold;
      }
      .nested-table table {
        width: 100%;
        margin: 10px 0;
      }
      .nested-table td {
        padding: 8px;
        font-size: 13px;
      }
      .runtime-output pre {
        white-space: pre-wrap;
        white-space: -moz-pre-wrap;
        white-space: -pre-wrap;
        white-space: -o-pre-wrap;
        word-wrap: break-word;
      }
      .visualizations img {
        max-width: 100%;
        margin: 10px 0;
        border: 1px solid #e0e0e0;
        border-radius: 4px;
      }
      .visualizations h3 {
        margin-top: 30px;
        margin-bottom: 15px;
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 5px;
      }
      
      /* Collapsible section styles */
      .collapsible {
        cursor: pointer;
        padding: 10px;
        background-color: #f0f0f0;
        border: 1px solid #ddd;
        border-radius: 4px;
        margin-bottom: 10px;
        user-select: none;
        display: flex;
        justify-content: space-between;
        align-items: center;
      }
      .collapsible:hover {
        background-color: #e8e8e8;
      }
      .collapsible::after {
        content: '▼';
        font-size: 12px;
        color: #666;
        transition: transform 0.3s;
      }
      .collapsible.collapsed::after {
        transform: rotate(-90deg);
      }
      .collapsible-content {
        max-height: 500px;
        overflow: auto;
        transition: max-height 0.3s ease;
        margin-bottom: 20px;
      }
      .collapsible-content.collapsed {
        max-height: 0;
        overflow: hidden;
      }
    </style>
    <script>
      function toggleCollapse(id) {
        const content = document.getElementById(id);
        const button = content.previousElementSibling;
        content.classList.toggle('collapsed');
        button.classList.toggle('collapsed');
      }
    </script>
  </head>
  <body>
    <div class="container">
      <h1>LLM Code Generation Report #10</h1>

      <div class="header-info">
        <p><b>Timestamp:</b> 2025-10-12 12:38:23</p>
        <p><b>Model:</b> x-ai/grok-4-fast</p>
        <p><b>Logprobs available:</b> True</p>
      </div>

      <h2>Selected User Stories</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('stories-content')">
        Click to expand/collapse
      </div>
      <div id="stories-content" class="collapsible-content collapsed">
        <pre>﻿As a Data user, I want to have the 12-19-2017 deletions processed.
As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles.
As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX.
As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership.
As a Developer , I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions.
As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed.
As a DevOps engineer, I want New Relic to provide useful data across all applications.
As a UI designer,  I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a Broker user, I want to Upload and Validate the error message to have accurate text.
As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don't have to regenerate a file if no data has been updated.
As a Website user, I want to access published FABS files, so that I can see the new files as they come in.
As an owner, I want to be sure that USAspending only send grant records to my system.
As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period.
As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues.
As a user, I want to access the raw agency published files from FABS via USAspending.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Broker user, I want  to help create content mockups, so that I can submit my data efficiently.
As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what want s to be fixed.
As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on.
As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests.
As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in.
As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted.
As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements want ed.
As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates.
As an data user, I want to receive updates to FABS records.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Developer , I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header.
As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
As a website user, I want to see updated financial assistance data daily.
As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission.
As a Developer , I want to ensure that attempts to correct or delete non-existent records don't create new published data.
As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access.
As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data.
As a Developer , I want to clarify to users what exactly is triggering the CFDA error code in each case.
As an agency user, I want to be confident that the data coming from SAM is complete.
As a Developer , I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time.
As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
As a broker team member, I want to make some updates to the SQL codes for clarity.
As an agency user, I want to have all derived data elements derived properly.
As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them.
As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table.
As a broker team member, I want to ensure the Broker resources, validations, and P&P pages are updated appropriately for the launch of FABS and DAIMS v1.1.
As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov.
As a user, I don't want to see NASA grants displayed as contracts.
As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired.
As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves.
As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
As an agency user, I want to use the schema v1.1 headers in my FABS file.
As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
As a FABS user, I want to link the SAMPLE FILE on the "What you want  to submit" dialog to point to the correct file, so that I have an accurate reference for my agency submissions.
As an Agency user, I want FPDS data to be up-to-date daily.
As a user, I want to access the raw agency published files from FABS via USAspending.
As a Developer , I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
As a user, I want to generate and validate D Files from FABS and FPDS data.
As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated.
As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment.
As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn't work.
As a FABS user, I want the frontend URLs to more accurately reflect the page I'm accessing, so that I'm not confused.
As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
As a Developer , I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
As an Agency user, I want historical FPDS data loaded.
As an Agency user, I want to accurately see who created a submission, so that I'm not confused about who last updated a submission.
As an agency user, I want to get File F in the correct format.
As an Agency user, I want to better understand my file-level errors.
As a Developer , I want to provide FABS groups that function under the FREC paradigm.
As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
As an owner, I only want zero-padded fields, so that I can justify padding.
As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
As a user, I want more information about how many rows will be published prior to deciding whether to publish.
As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.
As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.
As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct.
As a data user, I want to access two additional fields from the FPDS data pull.
As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests.
As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file.
As a Developer I want to quickly access Broker application data, so that I can investigate issues.
As a Developer , I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007.
As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused.
As a FABS user, I do not want  DABS banner messages and vice versa, so that I have the appropriate information for my application.
As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions.
As a FABS user, I want to have my validations run in a reasonable amount of time.
As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history.
As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends.
As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site.
As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won't strip off leading and trailing zeroes.</pre>
      </div>

      <h2>Prompt Sent to LLM</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('prompt-content')">
        Click to expand/collapse
      </div>
      <div id="prompt-content" class="collapsible-content collapsed">
        <pre>Generate fully functional Python code that implements the following user stories. The code should realistically reflect the described functionality.

﻿As a Data user, I want to have the 12-19-2017 deletions processed.
As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles.
As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX.
As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership.
As a Developer , I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions.
As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed.
As a DevOps engineer, I want New Relic to provide useful data across all applications.
As a UI designer,  I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a Broker user, I want to Upload and Validate the error message to have accurate text.
As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don't have to regenerate a file if no data has been updated.
As a Website user, I want to access published FABS files, so that I can see the new files as they come in.
As an owner, I want to be sure that USAspending only send grant records to my system.
As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period.
As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues.
As a user, I want to access the raw agency published files from FABS via USAspending.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Broker user, I want  to help create content mockups, so that I can submit my data efficiently.
As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what want s to be fixed.
As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on.
As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests.
As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in.
As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted.
As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements want ed.
As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates.
As an data user, I want to receive updates to FABS records.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Developer , I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header.
As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
As a website user, I want to see updated financial assistance data daily.
As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission.
As a Developer , I want to ensure that attempts to correct or delete non-existent records don't create new published data.
As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access.
As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data.
As a Developer , I want to clarify to users what exactly is triggering the CFDA error code in each case.
As an agency user, I want to be confident that the data coming from SAM is complete.
As a Developer , I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time.
As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
As a broker team member, I want to make some updates to the SQL codes for clarity.
As an agency user, I want to have all derived data elements derived properly.
As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them.
As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table.
As a broker team member, I want to ensure the Broker resources, validations, and P&P pages are updated appropriately for the launch of FABS and DAIMS v1.1.
As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov.
As a user, I don't want to see NASA grants displayed as contracts.
As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired.
As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves.
As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
As an agency user, I want to use the schema v1.1 headers in my FABS file.
As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
As a FABS user, I want to link the SAMPLE FILE on the "What you want  to submit" dialog to point to the correct file, so that I have an accurate reference for my agency submissions.
As an Agency user, I want FPDS data to be up-to-date daily.
As a user, I want to access the raw agency published files from FABS via USAspending.
As a Developer , I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
As a user, I want to generate and validate D Files from FABS and FPDS data.
As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated.
As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment.
As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn't work.
As a FABS user, I want the frontend URLs to more accurately reflect the page I'm accessing, so that I'm not confused.
As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
As a Developer , I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
As an Agency user, I want historical FPDS data loaded.
As an Agency user, I want to accurately see who created a submission, so that I'm not confused about who last updated a submission.
As an agency user, I want to get File F in the correct format.
As an Agency user, I want to better understand my file-level errors.
As a Developer , I want to provide FABS groups that function under the FREC paradigm.
As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
As an owner, I only want zero-padded fields, so that I can justify padding.
As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
As a user, I want more information about how many rows will be published prior to deciding whether to publish.
As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.
As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.
As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct.
As a data user, I want to access two additional fields from the FPDS data pull.
As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests.
As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file.
As a Developer I want to quickly access Broker application data, so that I can investigate issues.
As a Developer , I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007.
As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused.
As a FABS user, I do not want  DABS banner messages and vice versa, so that I have the appropriate information for my application.
As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions.
As a FABS user, I want to have my validations run in a reasonable amount of time.
As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history.
As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends.
As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site.
As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won't strip off leading and trailing zeroes.

Output only Python code (no markdown formatting or extra text). Do not leave functions empty — implement reasonable logic where needed.</pre>
      </div>

      <h2>Generated Code</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('code-content')">
        Click to expand/collapse
      </div>
      <div id="code-content" class="collapsible-content collapsed">
        <pre>import datetime
import json
import logging
import os
import sqlite3
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum

# Setup logging for better troubleshooting
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Database setup for data management
DB_FILE = 'usaspending.db'
conn = sqlite3.connect(DB_FILE, check_same_thread=False)
cursor = conn.cursor()

# Initialize database tables
cursor.execute('''
CREATE TABLE IF NOT EXISTS fabs_submissions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    submission_date DATE,
    publish_status TEXT,
    data TEXT,
    created_by TEXT,
    flexfields TEXT
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS historical_fabs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agency_code TEXT,
    frec_data TEXT,
    derived_fields TEXT
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS fpds_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    load_date DATE,
    data TEXT,
    extracted_historical TEXT
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS gtast_window (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    start_date DATE,
    end_date DATE,
    locked BOOLEAN
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS d_files_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    request_hash TEXT UNIQUE,
    generated_file TEXT,
    expiry_date DATE
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS validation_rules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rule_name TEXT,
    description TEXT,
    updated_for TEXT
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS user_testing (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    date DATE,
    summary TEXT,
    issues TEXT
)
''')

cursor.execute('''
CREATE TABLE IF NOT EXISTS flexfields (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    submission_id INTEGER,
    field_name TEXT,
    value TEXT,
    FOREIGN KEY(submission_id) REFERENCES fabs_submissions(id)
)
''')

conn.commit()

class PublishStatus(Enum):
    DRAFT = "draft"
    PUBLISHED = "published"
    REJECTED = "rejected"

@dataclass
class FABSSubmission:
    id: Optional[int]
    submission_date: datetime.date
    publish_status: PublishStatus
    data: Dict
    created_by: str
    flexfields: List[Dict] = None

    def to_dict(self):
        return asdict(self)

class Role(Enum):
    DATA_USER = "Data user"
    UI_DESIGNER = "UI designer"
    DEVELOPER = "Developer"
    DEVOPS = "DevOps engineer"
    BROKER_USER = "Broker user"
    WEBSITE_USER = "Website user"
    OWNER = "Owner"
    AGENCY_USER = "Agency user"
    TESTER = "Tester"
    FABS_USER = "FABS user"

class BrokerApp:
    def __init__(self):
        self.submissions: List[FABSSubmission] = []
        self.logged_issues = []
        self.new_relic_data = {}

    def process_12_19_2017_deletions(self):
        """As a Data user, I want to have the 12-19-2017 deletions processed."""
        logger.info("Processing deletions for 12-19-2017")
        cursor.execute("DELETE FROM fabs_submissions WHERE submission_date = '2017-12-19'")
        conn.commit()
        return len(cursor.rowcount)

    def redesign_resources_page(self):
        """As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles."""
        # Simulate UI redesign by generating a mock CSS/JSON style
        styles = {
            "color": "#007BFF",
            "font-family": "Arial, sans-serif",
            "layout": "flexbox"
        }
        logger.info(f"Redesigned Resources page with styles: {styles}")
        return styles

    def report_user_testing_to_agencies(self, summary: str):
        """As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX."""
        report = f"User testing summary: {summary}. Thanks for contributions!"
        logger.info(report)
        # Simulate sending report
        return report

    def move_to_round2_dabs_fabs_landing(self):
        """As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership."""
        edits = {"round": 2, "pages": ["DABS", "FABS"], "status": "Pending approval"}
        logger.info(f"Moving to round 2 edits: {edits}")
        return edits

    def move_to_round2_homepage(self):
        """As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership."""
        edits = {"page": "Homepage", "round": 2, "status": "Pending approval"}
        logger.info(f"Moving to round 2 homepage edits: {edits}")
        return edits

    def move_to_round3_help_page(self):
        """As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership."""
        edits = {"page": "Help", "round": 3, "status": "Pending approval"}
        logger.info(f"Moving to round 3 help page edits: {edits}")
        return edits

    def move_to_round2_help_page(self):
        """As a UI designer, I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership."""
        edits = {"page": "Help", "round": 2, "status": "Pending approval"}
        logger.info(f"Moving to round 2 help page edits: {edits}")
        return edits

    def improved_logging(self, message: str):
        """As a Developer, I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions."""
        logger.info(f"Enhanced log: {message}")
        self.logged_issues.append({"timestamp": datetime.datetime.now(), "message": message})
        return self.logged_issues[-1]

    def update_fabs_submission_on_status_change(self, submission_id: int, new_status: PublishStatus):
        """As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed."""
        cursor.execute("UPDATE fabs_submissions SET publish_status = ? WHERE id = ?", (new_status.value, submission_id))
        conn.commit()
        if cursor.rowcount > 0:
            logger.info(f"Updated submission {submission_id} to {new_status.value}")
            return True
        return False

    def new_relic_data_integration(self, app_name: str, data: Dict):
        """As a DevOps engineer, I want New Relic to provide useful data across all applications."""
        self.new_relic_data[app_name] = data
        logger.info(f"Integrated New Relic data for {app_name}: {data}")
        return self.new_relic_data

    def upload_validate_error_message(self, file_content: str):
        """As a Broker user, I want to Upload and Validate the error message to have accurate text."""
        errors = self.validate_file(file_content)
        accurate_message = f"Validation errors: {len(errors)}. Details: {errors}"
        logger.info(accurate_message)
        return accurate_message

    def sync_d1_file_generation(self, fpds_updated: bool):
        """As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don't have to regenerate a file if no data has been updated."""
        if not fpds_updated:
            logger.info("No FPDS update, using cached D1 file")
            return self.get_cached_d1_file()
        else:
            return self.generate_d1_file()

    def access_published_fabs_files(self) -> List[str]:
        """As a Website user, I want to access published FABS files, so that I can see the new files as they come in."""
        published = [s for s in self.submissions if s.publish_status == PublishStatus.PUBLISHED]
        files = [s.data.get('file_path', 'N/A') for s in published]
        logger.info(f"Accessed {len(files)} published FABS files")
        return files

    def ensure_only_grant_records_sent(self):
        """As an owner, I want to be sure that USAspending only send grant records to my system."""
        # Filter data to only grants
        filtered_data = {"type": "grant", "count": 100}
        logger.info(f"Ensured only grant records sent: {filtered_data}")
        return filtered_data

    def update_validation_rule_table(self, rule_update: str):
        """As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213."""
        cursor.execute("INSERT INTO validation_rules (rule_name, description, updated_for) VALUES (?, ?, ?)",
                       ("DB-2213", rule_update, "Updated"))
        conn.commit()
        logger.info(f"Updated validation rules for DB-2213: {rule_update}")
        return True

    def add_gtas_window_data(self, start_date: str, end_date: str):
        """As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period."""
        cursor.execute("INSERT INTO gtast_window (start_date, end_date, locked) VALUES (?, ?, ?)",
                       (start_date, end_date, True))
        conn.commit()
        logger.info(f"Added GTAS window: {start_date} to {end_date}")
        return True

    def manage_d_files_generation_cache(self, request_data: str) -> str:
        """As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues."""
        request_hash = hash(request_data)
        expiry = datetime.date.today() + datetime.timedelta(days=7)
        cursor.execute("SELECT generated_file FROM d_files_cache WHERE request_hash = ?", (request_hash,))
        cached = cursor.fetchone()
        if cached:
            logger.info("Using cached D file")
            return cached[0]
        else:
            file_content = self.generate_d_file(request_data)
            cursor.execute("INSERT OR REPLACE INTO d_files_cache (request_hash, generated_file, expiry_date) VALUES (?, ?, ?)",
                           (request_hash, file_content, expiry))
            conn.commit()
            return file_content

    def access_raw_agency_published_files(self) -> List[Dict]:
        """As a user, I want to access the raw agency published files from FABS via USAspending."""
        return self.access_published_fabs_files()  # Reuse

    def handle_large_flexfields_no_impact(self, flexfields: List[Dict], submission_id: int):
        """As an Agency user, I want to be able to include a large number of flexfields without performance impact."""
        for ff in flexfields:
            cursor.execute("INSERT INTO flexfields (submission_id, field_name, value) VALUES (?, ?, ?)",
                           (submission_id, ff['name'], json.dumps(ff['value'])))
        conn.commit()
        logger.info(f"Handled {len(flexfields)} flexfields for submission {submission_id}")
        return True

    def create_content_mockups(self, mockup_data: Dict):
        """As a Broker user, I want to help create content mockups, so that I can submit my data efficiently."""
        mockup = {"content": mockup_data, "generated": datetime.datetime.now()}
        logger.info(f"Created content mockup: {mockup}")
        return mockup

    def track_tech_thursday_issues(self, issues: List[str]):
        """As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what wants to be fixed."""
        self.logged_issues.extend([{"issue": i, "date": datetime.date.today()} for i in issues])
        logger.info(f"Tracked {len(issues)} Tech Thursday issues")
        return self.logged_issues[-len(issues):]

    def create_user_testing_summary(self, summary: str):
        """As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on."""
        cursor.execute("INSERT INTO user_testing (date, summary) VALUES (?, ?)",
                       (datetime.date.today(), summary))
        conn.commit()
        logger.info(f"Created user testing summary: {summary}")
        return summary

    def begin_user_testing(self, test_plan: str):
        """As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests."""
        test_entry = {"plan": test_plan, "status": "Started", "date": datetime.date.today()}
        cursor.execute("INSERT INTO user_testing (date, summary, issues) VALUES (?, ?, ?)",
                       (test_entry['date'], test_entry['plan'], "None"))
        conn.commit()
        logger.info(f"Began user testing: {test_plan}")
        return test_entry

    def schedule_user_testing(self, date: str):
        """As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in."""
        schedule = {"date": date, "status": "Scheduled"}
        logger.info(f"Scheduled user testing for {date}")
        return schedule

    def design_ui_improvement_schedule(self, timeline: Dict):
        """As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted."""
        design = {"schedule": timeline, "from": "UI SME"}
        logger.info(f"Designed UI schedule: {design}")
        return design

    def design_ui_audit_scope(self, scope: Dict):
        """As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements wanted."""
        audit = {"scope": scope, "from": "UI SME"}
        logger.info(f"Designed UI audit: {audit}")
        return audit

    def prevent_double_publishing_fabs(self, submission_id: int, publish_clicked: bool):
        """As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates."""
        cursor.execute("SELECT publish_status FROM fabs_submissions WHERE id = ?", (submission_id,))
        status = cursor.fetchone()
        if status and status[0] == PublishStatus.PUBLISHED.value and publish_clicked:
            logger.warning(f"Prevented double publish for {submission_id}")
            return False
        return True

    def receive_fabs_updates(self, updates: List[Dict]):
        """As an data user, I want to receive updates to FABS records."""
        for update in updates:
            cursor.execute("UPDATE fabs_submissions SET data = ? WHERE id = ?", (json.dumps(update), update.get('id')))
        conn.commit()
        logger.info(f"Received {len(updates)} FABS updates")
        return len(updates)

    def update_fabs_sample_file(self):
        """As a Developer, I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header."""
        sample_file = {
            "headers": ["ActionDate", "UniqueAwardID"],  # Removed FundingAgencyCode
            "sample_data": [["2023-01-01", "AWARD001"]]
        }
        with open('fabs_sample.csv', 'w') as f:
            f.write(json.dumps(sample_file))
        logger.info("Updated FABS sample file")
        return sample_file

    def ensure_deleted_fsrs_not_included(self):
        """As an agency user, I want to ensure that deleted FSRS records are not included in submissions."""
        # Simulate filtering
        filtered = {"records": "Only active FSRS"}
        logger.info(f"Ensured deleted FSRS not included: {filtered}")
        return filtered

    def update_financial_assistance_daily(self):
        """As a website user, I want to see updated financial assistance data daily."""
        today = datetime.date.today()
        cursor.execute("UPDATE fabs_submissions SET submission_date = ? WHERE publish_status = 'published'",
                       (today,))
        conn.commit()
        logger.info(f"Updated financial data for {today}")
        return True

    def deactivate_publish_button_during_derivations(self, submission_id: int):
        """As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission."""
        # Simulate button state
        state = {"submission_id": submission_id, "publish_button_active": False, "deriving": True}
        logger.info(f"Deactivated publish button for {submission_id}")
        return state

    def prevent_nonexistent_record_operations(self, record_id: int, operation: str):
        """As a Developer, I want to ensure that attempts to correct or delete non-existent records don't create new published data."""
        cursor.execute("SELECT id FROM fabs_submissions WHERE id = ?", (record_id,))
        if not cursor.fetchone():
            logger.warning(f"Prevented {operation} on non-existent record {record_id}")
            return False
        return True

    def reset_environment_permissions(self):
        """As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access."""
        permissions = {"env": "Staging", "max": True, "testers_access": False}
        logger.info(f"Reset permissions: {permissions}")
        return permissions

    def flexfields_in_error_files(self, submission_id: int, missing_element: str):
        """As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element."""
        errors = [{"type": "missing", "element": missing_element, "flexfields": self.get_flexfields(submission_id)}]
        logger.info(f"Included flexfields in errors for {submission_id}")
        return errors

    def ensure_ppopcode_ppocd_accuracy(self):
        """As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict."""
        derived = {"PPoPCode": "Accurate", "PPoPCongressionalDistrict": "Complete"}
        logger.info(f"Ensured PPoP data accuracy: {derived}")
        return derived

    def fabs_accept_zero_blank_loans(self, record: Dict):
        """As an agency user, I want the FABS validation rules to accept zero and blank for loan records."""
        if record.get('type') == 'loan' and (record.get('value') in [0, '']):
            return {"valid": True, "reason": "Accepted zero/blank for loans"}
        return self.validate_record(record)

    def deploy_fabs_production(self):
        """As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data."""
        deployment = {"status": "Deployed", "env": "Production"}
        logger.info(f"FABS deployed: {deployment}")
        return deployment

    def clarify_cfda_error_code(self, case: str):
        """As a Developer, I want to clarify to users what exactly is triggering the CFDA error code in each case."""
        clarifications = {
            "missing": "CFDA missing in required fields",
            "invalid": "CFDA format invalid"
        }
        explanation = clarifications.get(case, "Unknown case")
        logger.info(f"CFDA error clarification: {explanation}")
        return explanation

    def ensure_sam_data_complete(self):
        """As an agency user, I want to be confident that the data coming from SAM is complete."""
        completeness = {"sam_check": "Complete", "missing": []}
        logger.info(f"SAM data completeness: {completeness}")
        return completeness

    def index_domain_models(self):
        """As a Developer, I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time."""
        # Simulate indexing
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_submission_id ON fabs_submissions(id)")
        conn.commit()
        logger.info("Indexed domain models")
        return True

    def fabs_accept_zero_blank_nonloans(self, record: Dict):
        """As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records."""
        if record.get('type') != 'loan' and (record.get('value') in [0, '']):
            return {"valid": True, "reason": "Accepted zero/blank for non-loans"}
        return self.validate_record(record)

    def update_sql_codes_clarity(self, sql_code: str):
        """As a broker team member, I want to make some updates to the SQL codes for clarity."""
        updated_sql = f"-- Updated for clarity\n{sql_code}"
        logger.info(f"Updated SQL: {updated_sql[:50]}...")
        return updated_sql

    def derive_all_data_elements(self, record: Dict) -> Dict:
        """As an agency user, I want to have all derived data elements derived properly."""
        derived = record.copy()
        derived['derived_field'] = "Properly derived"
        logger.info(f"Derived elements for record: {derived}")
        return derived

    def add_00_ppopcode_cases(self, logic: Dict):
        """As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic."""
        logic['00_cases'] = ["00*****", "00FORGN"]
        logger.info(f"Added 00 PPoPCode cases: {logic}")
        return logic

    def derive_office_names(self, office_codes: List[str]) -> Dict:
        """As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them."""
        names = {code: f"Office of {code}" for code in office_codes}
        logger.info(f"Derived office names: {names}")
        return names

    def historical_fabs_loader_derive(self, historical_data: List[Dict]):
        """As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table."""
        for data in historical_data:
            derived = self.derive_all_data_elements(data)
            cursor.execute("INSERT INTO historical_fabs (agency_code, frec_data, derived_fields) VALUES (?, ?, ?)",
                           (derived.get('agency_code'), json.dumps(derived), json.dumps(derived)))
        conn.commit()
        logger.info(f"Loaded and derived {len(historical_data)} historical FABS records")
        return len(historical_data)

    def update_broker_resources_for_launch(self, updates: Dict):
        """As a broker team member, I want to ensure the Broker resources, validations, and P&P pages are updated appropriately for the launch of FABS and DAIMS v1.1."""
        for key, value in updates.items():
            if key == 'validations':
                self.update_validation_rule_table(value)
        logger.info("Updated for FABS and DAIMS v1.1 launch")
        return updates

    def load_historical_fabs_with_frec(self, data: List[Dict]):
        """As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov."""
        for item in data:
            item['frec'] = "Derived FREC"
            cursor.execute("INSERT INTO historical_fabs (agency_code, frec_data, derived_fields) VALUES (?, ?, ?)",
                           (item['agency'], json.dumps(item['frec']), json.dumps(item)))
        conn.commit()
        logger.info(f"Loaded historical FABS with FREC: {len(data)} records")
        return len(data)

    def prevent_nasa_grants_as_contracts(self):
        """As a user, I don't want to see NASA grants displayed as contracts."""
        display_filter = {"agency": "NASA", "type": "grant", "display_as": "grant"}
        logger.info(f"Prevented NASA grants as contracts: {display_filter}")
        return display_filter

    def duns_validation_accept_bcd(self, record: Dict):
        """As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired."""
        if record['ActionType'] in ['B', 'C', 'D'] and self.is_duns_registered(record['DUNS']):
            return {"valid": True, "reason": "Accepted expired SAM DUNS for B/C/D"}
        return self.validate_duns(record)

    def duns_validation_accept_past_dates(self, record: Dict):
        """As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date."""
        action_date = datetime.datetime.strptime(record['ActionDate'], '%Y-%m-%d').date()
        initial_reg = datetime.date(2000, 1, 1)  # Example
        current_reg = datetime.date.today()
        if initial_reg < action_date < current_reg and self.is_duns_registered(record['DUNS']):
            return {"valid": True, "reason": "Accepted past ActionDate"}
        return self.validate_duns(record)

    def derive_funding_agency_code(self, record: Dict) -> Dict:
        """As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves."""
        record['FundingAgencyCode'] = "Derived"
        logger.info(f"Derived FundingAgencyCode: {record}")
        return record

    def update_legal_entity_address_line3_length(self, schema_version: str):
        """As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1."""
        max_length = 100 if schema_version == "v1.1" else 50
        logger.info(f"Updated LegalEntityAddressLine3 max length to {max_length} for {schema_version}")
        return max_length

    def use_schema_v11_headers(self, file_headers: List[str]):
        """As an agency user, I want to use the schema v1.1 headers in my FABS file."""
        v11_headers = ["ActionDate", "UniqueAwardID", "LegalEntityAddressLine3"]  # Example
        if set(file_headers) == set(v11_headers):
            return {"valid": True}
        return {"valid": False, "expected": v11_headers}

    def map_federal_action_obligation_to_atom_feed(self, obligation: float):
        """As a agency user, I want to map the FederalActionObligation properly to the Atom Feed."""
        atom_map = {"obligation": obligation, "feed": "Atom"}
        logger.info(f"Mapped obligation to Atom Feed: {atom_map}")
        return atom_map

    def ppopzip4_same_as_legal_zip(self, zip4: str, legal_zip: str):
        """As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations."""
        validation = self.validate_zip(legal_zip) and self.validate_zip(zip4)
        logger.info(f"PPoPZIP+4 validation same as legal: {validation}")
        return validation

    def link_sample_file_correctly(self, dialog: Dict):
        """As a FABS user, I want to link the SAMPLE FILE on the "What you want to submit" dialog to point to the correct file, so that I have an accurate reference for my agency submissions."""
        dialog['sample_link'] = 'fabs_sample.csv'
        logger.info(f"Updated sample file link: {dialog}")
        return dialog

    def update_fpds_daily(self):
        """As an Agency user, I want FPDS data to be up-to-date daily."""
        today = datetime.date.today()
        cursor.execute("INSERT INTO fpds_data (load_date, data) VALUES (?, ?)",
                       (today, json.dumps({"daily_update": True})))
        conn.commit()
        logger.info(f"Updated FPDS for {today}")
        return True

    def determine_d_files_generation(self, agency_method: str):
        """As a Developer, I want to determine how agencies will generate and validate D Files from FABS and FPDS data."""
        method = {"agency_method": agency_method, "from": "FABS_FPDS"}
        logger.info(f"Determined D files generation: {method}")
        return method

    def generate_validate_d_files(self, fabs_data: Dict, fpds_data: Dict):
        """As a user, I want to generate and validate D Files from FABS and FPDS data."""
        d_file = self.manage_d_files_generation_cache(json.dumps({"fabs": fabs_data, "fpds": fpds_data}))
        validation = self.validate_file(d_file)
        logger.info(f"Generated and validated D file: {len(validation)} errors")
        return {"file": d_file, "errors": validation}

    def header_info_show_date_time(self, update_time: datetime.datetime):
        """As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated."""
        header = f"Updated: {update_time.strftime('%Y-%m-%d %H:%M:%S')}"
        logger.info(header)
        return header

    def helpful_file_level_error_wrong_extension(self, file_ext: str):
        """As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension."""
        if file_ext != '.csv':
            error = f"Invalid extension '{file_ext}'. Expected .csv. Please convert your file."
            logger.error(error)
            return error
        return None

    def access_test_features_other_envs(self, env: str, feature: str):
        """As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment."""
        access = env != "Production" and feature.startswith("test_")
        logger.info(f"Access to {feature} in {env}: {access}")
        return access

    def submission_errors_represent_fabs(self, errors: List[str]):
        """As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn't work."""
        fabs_errors = [e for e in errors if "FABS" in e]
        logger.info(f"FABS-specific errors: {fabs_errors}")
        return fabs_errors

    def frontend_urls_accurate(self, page: str):
        """As a FABS user, I want the frontend URLs to more accurately reflect the page I'm accessing, so that I'm not confused."""
        url_map = {
            "dashboard": "/fabs/dashboard",
            "submit": "/fabs/submit"
        }
        url = url_map.get(page, f"/fabs/{page}")
        logger.info(f"Accurate URL for {page}: {url}")
        return url

    def load_all_historical_financial_assistance(self):
        """As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live."""
        # Simulate loading
        count = 10000
        logger.info(f"Loaded {count} historical FA records for FABS go-live")
        return count

    def load_historical_fpds_mixed(self, historical: List[Dict], feed: List[Dict]):
        """As a Developer, I want the historical FPDS data loader to include both extracted historical data and FPDS feed data."""
        all_data = historical + feed
        for item in all_data:
            cursor.execute("INSERT INTO fpds_data (load_date, data, extracted_historical) VALUES (?, ?, ?)",
                           (datetime.date.today(), json.dumps(item), "historical" if item in historical else "feed"))
        conn.commit()
        logger.info(f"Loaded mixed historical FPDS: {len(all_data)} records")
        return len(all_data)

    def load_historical_fpds(self):
        """As an Agency user, I want historical FPDS data loaded."""
        return self.load_historical_fpds_mixed([], [])  # Placeholder

    def accurate_submission_creator(self, submission_id: int, creator: str):
        """As an Agency user, I want to accurately see who created a submission, so that I'm not confused about who last updated a submission."""
        cursor.execute("UPDATE fabs_submissions SET created_by = ? WHERE id = ?", (creator, submission_id))
        conn.commit()
        logger.info(f"Set creator {creator} for submission {submission_id}")
        return creator

    def get_file_f_correct_format(self):
        """As an agency user, I want to get File F in the correct format."""
        file_f = {"format": "Correct", "version": "1.1"}
        logger.info(f"Generated File F: {file_f}")
        return file_f

    def better_file_level_errors(self, errors: List[str]):
        """As an Agency user, I want to better understand my file-level errors."""
        detailed = [f"Level: File, Detail: {e}" for e in errors]
        logger.info(f"Detailed file errors: {detailed}")
        return detailed

    def provide_fabs_groups_frec(self):
        """As a Developer, I want to provide FABS groups that function under the FREC paradigm."""
        groups = {"frec_paradigm": True, "groups": ["FABS1", "FABS2"]}
        logger.info(f"Provided FREC FABS groups: {groups}")
        return groups

    def ensure_derivations_proper_test(self, test_file: str):
        """As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check."""
        derived = self.derive_all_data_elements(json.loads(test_file))
        check = all(key in derived for key in ['derived_field'])
        logger.info(f"Derivation test passed: {check}")
        return check

    def only_zero_padded_fields(self, data: Dict):
        """As an owner, I only want zero-padded fields, so that I can justify padding."""
        padded = {k: f"{v:05d}" if isinstance(v, int) else v for k, v in data.items()}
        logger.info(f"Applied zero-padding: {padded}")
        return padded

    def submit_individual_recipients_no_duns_error(self, recipient: Dict):
        """As a Broker user, I want to submit records for individual recipients without receiving a DUNS error."""
        if recipient.get('type') == 'individual':
            return {"valid": True, "duns_error": False}
        return self.validate_duns(recipient)

    def more_info_rows_before_publish(self, submission: FABSSubmission):
        """As a user, I want more information about how many rows will be published prior to deciding whether to publish."""
        rows = len(json.loads(submission.data).get('rows', []))
        info = f"Rows to publish: {rows}"
        logger.info(info)
        return info

    def prevent_duplicate_transactions(self, transaction: Dict):
        """As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision."""
        cursor.execute("SELECT id FROM fabs_submissions WHERE data = ?", (json.dumps(transaction),))
        if cursor.fetchone():
            logger.warning("Prevented duplicate transaction")
            return False
        return True

    def submit_citywide_ppopzip(self, zip_code: str):
        """As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations."""
        if "citywide" in zip_code.lower():
            return {"valid": True, "reason": "Citywide ZIP accepted"}
        return self.validate_zip(zip_code)

    def updated_error_codes(self, errors: List[Dict]):
        """As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission."""
        updated = [e | {"info": "Detailed logic explanation"} for e in errors]
        logger.info(f"Updated error codes: {updated}")
        return updated

    def leave_off_last4_zip_no_error(self, zip5: str):
        """As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions."""
        if len(zip5) == 5:
            return {"valid": True, "reason": "5-digit ZIP accepted"}
        return self.validate_zip(zip5)

    def historical_data_all_columns(self):
        """As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct."""
        required_cols = ["agency", "frec", "derived"]
        columns = [desc[0] for desc in cursor.execute("PRAGMA table_info(historical_fabs)").fetchall()]
        complete = all(col in columns for col in required_cols)
        logger.info(f"Historical data columns complete: {complete}")
        return complete

    def access_additional_fpds_fields(self, fields: List[str]):
        """As a data user, I want to access two additional fields from the FPDS data pull."""
        additional = {"fields": fields, "from": "FPDS"}
        logger.info(f"Accessed additional FPDS fields: {additional}")
        return additional

    def additional_submission_dashboard_info(self, dashboard: Dict):
        """As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests."""
        dashboard['extra_info'] = {"pending": 5, "ig_requests": 2}
        logger.info(f"Updated dashboard: {dashboard}")
        return dashboard

    def download_uploaded_fabs_file(self, submission_id: int):
        """As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file."""
        cursor.execute("SELECT data FROM fabs_submissions WHERE id = ?", (submission_id,))
        file_data = cursor.fetchone()
        if file_data:
            # Simulate download
            with open(f'fabs_{submission_id}.json', 'w') as f:
                f.write(file_data[0])
            logger.info(f"Downloaded file for {submission_id}")
            return f'fabs_{submission_id}.json'
        return None

    def quick_access_broker_data(self, data_type: str):
        """As a Developer I want to quickly access Broker application data, so that I can investigate issues."""
        if data_type == 'submissions':
            return [s.to_dict() for s in self.submissions]
        return []

    def determine_load_historical_fpds(self):
        """As a Developer, I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007."""
        method = "Batch load since 2007"
        logger.info(f"Best method for historical FPDS: {method}")
        return method

    def appropriate_fabs_language(self, page_content: str):
        """As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused."""
        if "confusing" in page_content.lower():
            page_content = page_content.replace("confusing term", "clear term")
        logger.info(f"Updated language: {page_content}")
        return page_content

    def no_cross_banner_messages(self, app: str):
        """As a FABS user, I do not want DABS banner messages and vice versa, so that I have the appropriate information for my application."""
        banners = {"FABS": "FABS messages only", "DABS": "DABS messages only"}
        appropriate = banners.get(app, "No banners")
        logger.info(f"Appropriate banners for {app}: {appropriate}")
        return appropriate

    def fabs_readonly_dabs(self):
        """As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions."""
        access = {"FABS": "Full", "DABS": "Read-only"}
        logger.info(f"Set access: {access}")
        return access

    def reasonable_validation_time(self, file_data: str):
        """As a FABS user, I want to have my validations run in a reasonable amount of time."""
        start = datetime.datetime.now()
        errors = self.validate_file(file_data)
        time_taken = (datetime.datetime.now() - start).total_seconds()
        if time_taken > 10:
            logger.warning(f"Validation slow: {time_taken}s")
        logger.info(f"Validation completed in {time_taken}s with {len(errors)} errors")
        return {"time": time_taken, "errors": errors}

    def correct_status_labels_dashboard(self):
        """As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history."""
        labels = {s.publish_status.value: s.id for s in self.submissions}
        logger.info(f"Dashboard status labels: {labels}")
        return labels

    def submission_periods_start_end(self):
        """As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends."""
        periods = {"start": "2023-01-01", "end": "2023-12-31"}
        logger.info(f"Submission periods: {periods}")
        return periods

    def landing_page_nav_fabs_dabs(self):
        """As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site."""
        nav = {"landing": True, "links": ["/fabs", "/dabs"]}
        logger.info(f"Landing page nav: {nav}")
        return nav

    def submit_data_with_quotes(self, data: str):
        """As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won't strip off leading and trailing zeroes."""
        quoted_data = f'"{data}"'
        # Simulate submission
        logger.info(f"Submitted quoted data: {quoted_data}")
        return quoted_data

    # Helper methods
    def validate_file(self, content: str) -> List[str]:
        return ["Error: Invalid format"] if "invalid" in content else []

    def get_cached_d1_file(self) -> str:
        return "Cached D1 file content"

    def generate_d1_file(self) -> str:
        return "Generated D1 file content"

    def generate_d_file(self, data: str) -> str:
        return f"D file from {data}"

    def validate_record(self, record: Dict) -> Dict:
        return {"valid": True}

    def validate_duns(self, record: Dict) -> Dict:
        return {"valid": record.get('DUNS') is not None}

    def is_duns_registered(self, duns: str) -> bool:
        return True  # Mock

    def validate_zip(self, zip_code: str) -> bool:
        return len(zip_code) in [5, 9]

    def get_flexfields(self, submission_id: int) -> List[Dict]:
        cursor.execute("SELECT field_name, value FROM flexfields WHERE submission_id = ?", (submission_id,))
        return [{"name": row[0], "value": row[1]} for row in cursor.fetchall()]

# Example usage to make it functional
if __name__ == "__main__":
    app = BrokerApp()
    
    # Process some stories
    app.process_12_19_2017_deletions()
    app.redesign_resources_page()
    app.report_user_testing_to_agencies("Positive feedback on UX")
    app.move_to_round2_dabs_fabs_landing()
    app.move_to_round2_homepage()
    app.move_to_round3_help_page()
    app.move_to_round2_help_page()
    
    # Add a sample submission
    sample_submission = FABSSubmission(
        None, datetime.date.today(), PublishStatus.DRAFT,
        {"rows": [{}]}, "Test User"
    )
    cursor.execute("INSERT INTO fabs_submissions (submission_date, publish_status, data, created_by) VALUES (?, ?, ?, ?)",
                   (sample_submission.submission_date, sample_submission.publish_status.value,
                    json.dumps(sample_submission.data), sample_submission.created_by))
    conn.commit()
    submission_id = cursor.lastrowid
    app.submissions.append(sample_submission)
    
    app.improved_logging("Test log entry")
    app.update_fabs_submission_on_status_change(submission_id, PublishStatus.PUBLISHED)
    app.new_relic_data_integration("Broker", {"metrics": "ok"})
    print(app.upload_validate_error_message("valid file"))
    print(app.sync_d1_file_generation(fpds_updated=False))
    print(app.access_published_fabs_files())
    
    # Continue with more if needed, but keep it reasonable
    conn.close()</pre>
      </div>

      <h2>Confidence & Basic Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Total completion tokens</th>
            <td>10080</td>
          </tr>
          <tr>
            <th>Total log-probability</th>
            <td>-792.009</td>
          </tr>
          <tr>
            <th>Average per-token probability</th>
            <td>92.44%</td>
          </tr>
          <tr>
            <th>Perplexity</th>
            <td>1.08</td>
          </tr>
        </table>
      </div>

      <h2>Code Structure & Length Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Function count (AST)</th>
            <td>106</td>
          </tr>
          <tr>
            <th>Class count (AST)</th>
            <td>4</td>
          </tr>
          <tr>
            <th>Number of lines</th>
            <td>870</td>
          </tr>
          <tr>
            <th>Non-empty lines</th>
            <td>745</td>
          </tr>
          <tr>
            <th>Avg line length (all lines, chars)</th>
            <td>
              48.5
            </td>
          </tr>
          <tr>
            <th>Avg line length (non-empty, chars)</th>
            <td>
              56.6
            </td>
          </tr>
          <tr>
            <th>Avg tokens per non-empty line</th>
            <td>
              6.17
            </td>
          </tr>
          <tr>
            <th>AST depth (max nesting)</th>
            <td>12</td>
          </tr>
          <tr>
            <th>Import count</th>
            <td>8</td>
          </tr>
          <tr>
            <th>Import names</th>
            <td>dataclasses, datetime, enum, json, logging, os, sqlite3, typing</td>
          </tr>
          <tr>
            <th>Avg cyclomatic complexity (functions)</th>
            <td>
              1.51
            </td>
          </tr>
          <tr>
            <th>Max cyclomatic complexity (functions)</th>
            <td>4</td>
          </tr>
          <tr>
            <th>Module cyclomatic complexity</th>
            <td>166</td>
          </tr>
          <tr>
            <th>Average function size (lines)</th>
            <td>
              5.7
            </td>
          </tr>
          <tr>
            <th>Comment density (%)</th>
            <td>
              2.3%
            </td>
          </tr>
          <tr>
            <th>Import redundancy ratio</th>
            <td>
              0.00
            </td>
          </tr>
        </table>
      </div>

      <h2>Semantic Quality Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Syntax valid</th>
            <td>True</td>
          </tr>
          <tr>
            <th>Flake8 style errors</th>
            <td>11</td>
          </tr>
          <tr>
            <th>Flake8 errors (by category)</th>
            <td>
              <div class="nested-table">
                <table>
                  <tr>
                    <th>Style errors (PEP8 spacing, indentation, etc.) (E)</th>
                    <td>
                      5
                    </td>
                  </tr>
                  <tr>
                    <th>
                      Logical errors (undefined vars, unused imports, etc.) (F)
                    </th>
                    <td>
                      1
                    </td>
                  </tr>
                  <tr>
                    <th>Warnings (whitespace, etc.) (W)</th>
                    <td>
                      5
                    </td>
                  </tr>
                  <tr>
                    <th>McCabe complexity issues (C)</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Naming conventions (N)</th>
                    <td>
                      0
                    </td>
                  </tr>
                </table>
              </div>
            </td>
          </tr>
          <tr>
            <th>Mypy type-check errors</th>
            <td>4</td>
          </tr>
          <tr>
            <th>Mypy error breakdown</th>
            <td>
              <div class="nested-table">
                <table>
                  <tr>
                    <th>Return type</th>
                    <td>
                      1
                    </td>
                  </tr>
                  <tr>
                    <th>Argument type</th>
                    <td>
                      2
                    </td>
                  </tr>
                  <tr>
                    <th>Missing return</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Attribute</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Annotation</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Other</th>
                    <td>
                      1
                    </td>
                  </tr>
                </table>
              </div>
            </td>
          </tr>
          <tr>
            <th>Semantic quality score (0–100)</th>
            <td>90.5</td>
          </tr>
        </table>
      </div>

      <h2>Execution-Based Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Execution success</th>
            <td>False</td>
          </tr>
          <tr>
            <th>Execution time (s)</th>
            <td>
              1.553
            </td>
          </tr>
          <tr>
            <th>Exception type</th>
            <td>TypeError</td>
          </tr>
          <tr>
            <th>Exception message</th>
            <td>object of type 'int' has no len()</td>
          </tr>
          <tr>
            <th>Runtime output (preview)</th>
            <td>
              <div class="runtime-output">
                <pre>2025-10-12 12:15:59,316 - INFO - Processing deletions for 12-19-2017
Traceback (most recent call last):
  File "/app/code.py", line 842, in <module>
    app.process_12_19_2017_deletions()
  File "/app/code.py", line 137, in process_12_19_2017_deletions
    return len(cursor.rowcount)
           ^^^^^^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()</pre>
              </div>
            </td>
          </tr>
        </table>
      </div>
      
      <h2>Total Credibility (0-100%)</h2>
      <p><b>Credibility:</b> 53.27%</p>

      <h2>Visualizations</h2>
      <div class="visualizations">
        <h3>Basic Confidence Metrics</h3>
        <img src="1_logprob_trend.png" alt="Log Probability Trend" />
        <img src="2_probability_distribution.png" alt="Probability Distribution" />
        <img src="3_cumulative_logprob.png" alt="Cumulative Log Probability" />
        
        <h3>Advanced Analysis</h3>
        <img src="4_smoothed_confidence.png" alt="Smoothed Confidence Trend" />
        <img src="5_uncertainty_heatmap.png" alt="Uncertainty Detection" />
        <img src="6_rolling_perplexity.png" alt="Rolling Perplexity" />
        
        <h3>Segmented Analysis</h3>
        <img src="7_confidence_by_segment.png" alt="Confidence by Segment" />
        <img src="8_confidence_by_token_type.png" alt="Confidence by Token Type" />
        <img src="9_confidence_volatility.png" alt="Confidence Volatility" />
        <img src="10_top_uncertain_tokens.png" alt="Top Uncertain Tokens" />
      </div>
    </div>
  </body>
</html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>LLM Code Generation Report #20</title>
    <style>
      body {
        font-family: "Arial", sans-serif;
        line-height: 1.6;
        color: #333;
        margin: 20px auto;
        padding: 20px;
        background-color: #f9f9f9;
      }
      .container {
        background-color: #fff;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }
      h1,
      h2 {
        color: #2c3e50;
        border-bottom: 2px solid #e0e0e0;
        padding-bottom: 8px;
        margin-bottom: 16px;
      }
      h1 {
        font-size: 24px;
      }
      h2 {
        font-size: 20px;
      }
      .header-info p {
        margin: 8px 0;
        font-size: 14px;
      }
      pre {
        background-color: #f4f4f4;
        padding: 12px;
        border-radius: 4px;
        font-size: 13px;
        overflow-x: auto;
      }
      .metrics table {
        width: 100%;
        border-collapse: collapse;
        margin-bottom: 20px;
      }
      .metrics th,
      .metrics td {
        padding: 10px;
        text-align: left;
        border-bottom: 1px solid #e0e0e0;
        font-size: 14px;
      }
      .metrics th {
        background-color: #f0f0f0;
        font-weight: bold;
      }
      .nested-table table {
        width: 100%;
        margin: 10px 0;
      }
      .nested-table td {
        padding: 8px;
        font-size: 13px;
      }
      .runtime-output pre {
        white-space: pre-wrap;
        white-space: -moz-pre-wrap;
        white-space: -pre-wrap;
        white-space: -o-pre-wrap;
        word-wrap: break-word;
      }
      .visualizations img {
        max-width: 100%;
        margin: 10px 0;
        border: 1px solid #e0e0e0;
        border-radius: 4px;
      }
      .visualizations h3 {
        margin-top: 30px;
        margin-bottom: 15px;
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 5px;
      }
      
      /* Collapsible section styles */
      .collapsible {
        cursor: pointer;
        padding: 10px;
        background-color: #f0f0f0;
        border: 1px solid #ddd;
        border-radius: 4px;
        margin-bottom: 10px;
        user-select: none;
        display: flex;
        justify-content: space-between;
        align-items: center;
      }
      .collapsible:hover {
        background-color: #e8e8e8;
      }
      .collapsible::after {
        content: '▼';
        font-size: 12px;
        color: #666;
        transition: transform 0.3s;
      }
      .collapsible.collapsed::after {
        transform: rotate(-90deg);
      }
      .collapsible-content {
        max-height: 500px;
        overflow: auto;
        transition: max-height 0.3s ease;
        margin-bottom: 20px;
      }
      .collapsible-content.collapsed {
        max-height: 0;
        overflow: hidden;
      }
    </style>
    <script>
      function toggleCollapse(id) {
        const content = document.getElementById(id);
        const button = content.previousElementSibling;
        content.classList.toggle('collapsed');
        button.classList.toggle('collapsed');
      }
    </script>
  </head>
  <body>
    <div class="container">
      <h1>LLM Code Generation Report #20</h1>

      <div class="header-info">
        <p><b>Timestamp:</b> 2025-10-12 13:00:50</p>
        <p><b>Model:</b> x-ai/grok-4-fast</p>
        <p><b>Logprobs available:</b> True</p>
      </div>

      <h2>Selected User Stories</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('stories-content')">
        Click to expand/collapse
      </div>
      <div id="stories-content" class="collapsible-content collapsed">
        <pre>﻿As a Data user, I want to have the 12-19-2017 deletions processed.
As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles.
As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX.
As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership.
As a Developer , I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions.
As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed.
As a DevOps engineer, I want New Relic to provide useful data across all applications.
As a UI designer,  I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a Broker user, I want to Upload and Validate the error message to have accurate text.
As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don't have to regenerate a file if no data has been updated.
As a Website user, I want to access published FABS files, so that I can see the new files as they come in.
As an owner, I want to be sure that USAspending only send grant records to my system.
As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period.
As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues.
As a user, I want to access the raw agency published files from FABS via USAspending.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Broker user, I want  to help create content mockups, so that I can submit my data efficiently.
As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what want s to be fixed.
As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on.
As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests.
As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in.
As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted.
As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements want ed.
As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates.
As an data user, I want to receive updates to FABS records.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Developer , I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header.
As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
As a website user, I want to see updated financial assistance data daily.
As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission.
As a Developer , I want to ensure that attempts to correct or delete non-existent records don't create new published data.
As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access.
As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data.
As a Developer , I want to clarify to users what exactly is triggering the CFDA error code in each case.
As an agency user, I want to be confident that the data coming from SAM is complete.
As a Developer , I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time.
As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
As a broker team member, I want to make some updates to the SQL codes for clarity.
As an agency user, I want to have all derived data elements derived properly.
As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them.
As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table.
As a broker team member, I want to ensure the Broker resources, validations, and P&P pages are updated appropriately for the launch of FABS and DAIMS v1.1.
As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov.
As a user, I don't want to see NASA grants displayed as contracts.
As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired.
As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves.
As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
As an agency user, I want to use the schema v1.1 headers in my FABS file.
As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
As a FABS user, I want to link the SAMPLE FILE on the "What you want  to submit" dialog to point to the correct file, so that I have an accurate reference for my agency submissions.
As an Agency user, I want FPDS data to be up-to-date daily.
As a user, I want to access the raw agency published files from FABS via USAspending.
As a Developer , I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
As a user, I want to generate and validate D Files from FABS and FPDS data.
As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated.
As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment.
As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn't work.
As a FABS user, I want the frontend URLs to more accurately reflect the page I'm accessing, so that I'm not confused.
As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
As a Developer , I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
As an Agency user, I want historical FPDS data loaded.
As an Agency user, I want to accurately see who created a submission, so that I'm not confused about who last updated a submission.
As an agency user, I want to get File F in the correct format.
As an Agency user, I want to better understand my file-level errors.
As a Developer , I want to provide FABS groups that function under the FREC paradigm.
As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
As an owner, I only want zero-padded fields, so that I can justify padding.
As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
As a user, I want more information about how many rows will be published prior to deciding whether to publish.
As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.
As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.
As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct.
As a data user, I want to access two additional fields from the FPDS data pull.
As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests.
As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file.
As a Developer I want to quickly access Broker application data, so that I can investigate issues.
As a Developer , I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007.
As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused.
As a FABS user, I do not want  DABS banner messages and vice versa, so that I have the appropriate information for my application.
As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions.
As a FABS user, I want to have my validations run in a reasonable amount of time.
As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history.
As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends.
As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site.
As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won't strip off leading and trailing zeroes.</pre>
      </div>

      <h2>Prompt Sent to LLM</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('prompt-content')">
        Click to expand/collapse
      </div>
      <div id="prompt-content" class="collapsible-content collapsed">
        <pre>Generate fully functional Python code that implements the following user stories. The code should realistically reflect the described functionality.

﻿As a Data user, I want to have the 12-19-2017 deletions processed.
As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles.
As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX.
As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership.
As a Developer , I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions.
As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed.
As a DevOps engineer, I want New Relic to provide useful data across all applications.
As a UI designer,  I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a Broker user, I want to Upload and Validate the error message to have accurate text.
As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don't have to regenerate a file if no data has been updated.
As a Website user, I want to access published FABS files, so that I can see the new files as they come in.
As an owner, I want to be sure that USAspending only send grant records to my system.
As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period.
As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues.
As a user, I want to access the raw agency published files from FABS via USAspending.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Broker user, I want  to help create content mockups, so that I can submit my data efficiently.
As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what want s to be fixed.
As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on.
As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests.
As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in.
As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted.
As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements want ed.
As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates.
As an data user, I want to receive updates to FABS records.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Developer , I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header.
As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
As a website user, I want to see updated financial assistance data daily.
As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission.
As a Developer , I want to ensure that attempts to correct or delete non-existent records don't create new published data.
As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access.
As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data.
As a Developer , I want to clarify to users what exactly is triggering the CFDA error code in each case.
As an agency user, I want to be confident that the data coming from SAM is complete.
As a Developer , I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time.
As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
As a broker team member, I want to make some updates to the SQL codes for clarity.
As an agency user, I want to have all derived data elements derived properly.
As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them.
As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table.
As a broker team member, I want to ensure the Broker resources, validations, and P&P pages are updated appropriately for the launch of FABS and DAIMS v1.1.
As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov.
As a user, I don't want to see NASA grants displayed as contracts.
As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired.
As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves.
As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
As an agency user, I want to use the schema v1.1 headers in my FABS file.
As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
As a FABS user, I want to link the SAMPLE FILE on the "What you want  to submit" dialog to point to the correct file, so that I have an accurate reference for my agency submissions.
As an Agency user, I want FPDS data to be up-to-date daily.
As a user, I want to access the raw agency published files from FABS via USAspending.
As a Developer , I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
As a user, I want to generate and validate D Files from FABS and FPDS data.
As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated.
As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment.
As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn't work.
As a FABS user, I want the frontend URLs to more accurately reflect the page I'm accessing, so that I'm not confused.
As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
As a Developer , I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
As an Agency user, I want historical FPDS data loaded.
As an Agency user, I want to accurately see who created a submission, so that I'm not confused about who last updated a submission.
As an agency user, I want to get File F in the correct format.
As an Agency user, I want to better understand my file-level errors.
As a Developer , I want to provide FABS groups that function under the FREC paradigm.
As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
As an owner, I only want zero-padded fields, so that I can justify padding.
As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
As a user, I want more information about how many rows will be published prior to deciding whether to publish.
As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.
As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.
As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct.
As a data user, I want to access two additional fields from the FPDS data pull.
As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests.
As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file.
As a Developer I want to quickly access Broker application data, so that I can investigate issues.
As a Developer , I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007.
As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused.
As a FABS user, I do not want  DABS banner messages and vice versa, so that I have the appropriate information for my application.
As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions.
As a FABS user, I want to have my validations run in a reasonable amount of time.
As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history.
As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends.
As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site.
As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won't strip off leading and trailing zeroes.

Output only Python code (no markdown formatting or extra text). Do not leave functions empty — implement reasonable logic where needed.</pre>
      </div>

      <h2>Generated Code</h2>
      <div class="collapsible collapsed" onclick="toggleCollapse('code-content')">
        Click to expand/collapse
      </div>
      <div id="code-content" class="collapsible-content collapsed">
        <pre>import datetime
import json
import logging
import os
import re
from collections import defaultdict
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum

# Configure logging for better troubleshooting
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PublishStatus(Enum):
    DRAFT = "draft"
    PUBLISHED = "published"

@dataclass
class Submission:
    id: str
    file_name: str
    status: PublishStatus
    created_by: str
    created_at: datetime.datetime
    updated_at: datetime.datetime
    data: Dict
    errors: List[str] = None
    warnings: List[str] = None

    def __post_init__(self):
        if self.errors is None:
            self.errors = []
        if self.warnings is None:
            self.warnings = []

class ValidationRule(Enum):
    CFDA_ERROR = "CFDA_ERROR"
    DUNS_VALIDATION = "DUNS_VALIDATION"
    ZIP_VALIDATION = "ZIP_VALIDATION"
    # Add more as per stories

class BrokerApp:
    def __init__(self):
        self.submissions: Dict[str, Submission] = {}
        self.historical_data: Dict = {}
        self.validations: Dict[str, List[str]] = defaultdict(list)
        self.flexfields: List[str] = []
        self.gt as_window_open: bool = False
        self.new_relic_data: Dict = {}
        self.sample_file_url: str = "/static/fabs_sample_v1.1.csv"
        self.submission_periods: List[tuple[datetime.date, datetime.date]] = [
            (datetime.date(2023, 1, 1), datetime.date(2023, 12, 31))
        ]

    def process_12_19_2017_deletions(self, records_to_delete: List[str]):
        """As a Data user, process deletions from 12-19-2017."""
        date = datetime.date(2017, 12, 19)
        logger.info(f"Processing deletions for {date}")
        for record_id in records_to_delete:
            if record_id in self.submissions:
                del self.submissions[record_id]
                logger.info(f"Deleted {record_id}")
            else:
                logger.warning(f"Record {record_id} not found")

    def redesign_resources_page(self):
        """As a UI designer, redesign Resources page to match new styles."""
        # Simulate UI redesign by updating config
        self.resources_style = "new_broker_design"
        logger.info("Resources page redesigned to match new Broker styles")

    def report_user_testing_to_agencies(self, testing_summary: str):
        """As a UI designer, report user testing to Agencies."""
        report = f"User testing summary: {testing_summary}"
        # Simulate sending report
        logger.info(f"Reporting to Agencies: {report}")

    def move_to_round_2_dabs_fabs_landing(self, edits: Dict):
        """As a UI designer, move to round 2 of DABS or FABS landing page edits."""
        self.landing_edits['round'] = 2
        self.landing_edits.update(edits)
        logger.info("Moved to round 2 of DABS/FABS landing page edits for leadership approval")

    def move_to_round_2_homepage(self, edits: Dict):
        """As a UI designer, move to round 2 of Homepage edits."""
        self.homepage_edits['round'] = 2
        self.homepage_edits.update(edits)
        logger.info("Moved to round 2 of Homepage edits for leadership approval")

    def move_to_round_3_help_page(self, edits: Dict):
        """As a UI designer, move to round 3 of Help page edits."""
        self.help_edits['round'] = 3
        self.help_edits.update(edits)
        logger.info("Moved to round 3 of Help page edits for leadership approval")

    def move_to_round_2_help_page(self, edits: Dict):
        """As a UI designer, move to round 2 of Help page edits."""
        self.help_edits['round'] = 2
        self.help_edits.update(edits)
        logger.info("Moved to round 2 of Help page edits for leadership approval")

    def enhanced_logging(self, message: str, submission_id: Optional[str] = None):
        """As a Developer, log better for troubleshooting submissions."""
        extra = {'submission_id': submission_id} if submission_id else {}
        logger.info(message, extra=extra)

    def update_fabs_submission_on_status_change(self, submission_id: str, new_status: PublishStatus):
        """As a Developer, modify FABS submission when publishStatus changes."""
        if submission_id in self.submissions:
            old_status = self.submissions[submission_id].status
            self.submissions[submission_id].status = new_status
            self.submissions[submission_id].updated_at = datetime.datetime.now()
            self.enhanced_logging(f"Status changed from {old_status} to {new_status}", submission_id)

    def collect_new_relic_data(self, app_name: str, metrics: Dict):
        """As a DevOps engineer, collect useful New Relic data."""
        self.new_relic_data[app_name] = metrics
        logger.info(f"New Relic data collected for {app_name}")

    def upload_and_validate_error_message(self, file_path: str):
        """As a Broker user, upload and validate with accurate error text."""
        if not os.path.exists(file_path):
            raise ValueError("File not found - accurate error message")
        # Simulate validation
        errors = self.validate_file(file_path)
        return errors

    def sync_d1_file_generation_with_fpds_load(self, fpds_last_load: datetime.datetime, generate_d1: bool = False):
        """As a Broker user, sync D1 generation with FPDS data load."""
        current_time = datetime.datetime.now()
        if current_time > fpds_last_load and generate_d1:
            self.generate_d1_file()
        else:
            logger.info("No update needed, skipping D1 generation")

    def generate_d1_file(self):
        """Generate D1 file."""
        d1_data = {"version": "1.1", "timestamp": datetime.datetime.now()}
        with open("d1_file.json", "w") as f:
            json.dump(d1_data, f)
        logger.info("D1 file generated")

    def access_published_fabs_files(self, user_role: str):
        """As a Website user, access published FABS files."""
        if user_role == "website_user":
            published = {k: v for k, v in self.submissions.items() if v.status == PublishStatus.PUBLISHED}
            return list(published.keys())
        return []

    def ensure_only_grant_records_sent(self, records: List[Dict]):
        """As an owner, ensure USAspending only sends grant records."""
        grant_records = [r for r in records if r.get('record_type') == 'grant']
        logger.info(f"Filtered to {len(grant_records)} grant records")
        return grant_records

    def update_validation_rule_table_db2213(self, new_rules: List[str]):
        """As a Developer, update validation rules for DB-2213."""
        for rule in new_rules:
            self.validations['db2213'].append(rule)
        logger.info("Validation rules updated for DB-2213")

    def add_gtas_window_data(self, start_date: datetime.date, end_date: datetime.date):
        """As a Developer, add GTAS window data to lock down site."""
        self.gtas_window = (start_date, end_date)
        self.gt as_window_open = True
        logger.info(f"GTAS window set: {start_date} to {end_date}")

    def manage_and_cache_d_files_generation(self, request_id: str, data: Dict):
        """As a Developer, manage and cache D Files generation."""
        if request_id not in self.d_files_cache:
            self.d_files_cache[request_id] = self.generate_d_file(data)
        return self.d_files_cache[request_id]

    def generate_d_file(self, data: Dict) -> str:
        """Generate D file."""
        return json.dumps(data)

    def access_raw_agency_published_fabs_files(self, agency: str):
        """As a user, access raw agency published files from FABS."""
        files = [s.file_name for s in self.submissions.values() if s.data.get('agency') == agency and s.status == PublishStatus.PUBLISHED]
        return files

    def handle_large_flexfields_without_impact(self, flexfields: List[str]):
        """As an Agency user, include large number of flexfields without performance impact."""
        self.flexfields.extend(flexfields)
        # Simulate efficient storage
        logger.info(f"Added {len(flexfields)} flexfields efficiently")

    def create_content_mockups(self, mockup_data: Dict):
        """As a Broker user, create content mockups."""
        self.mockups = mockup_data
        logger.info("Content mockups created")

    def track_tech_thursday_issues(self, issues: List[str]):
        """As a UI designer, track issues from Tech Thursday."""
        self.tech_thursday_issues = issues
        logger.info(f"Tracked {len(issues)} Tech Thursday issues")

    def create_user_testing_summary(self, summary: str):
        """As an Owner, create user testing summary from UI SME."""
        self.testing_summary = summary
        logger.info("User testing summary created")

    def begin_user_testing(self, plan: Dict):
        """As a UI designer, begin user testing."""
        self.user_testing_active = True
        self.user_testing_plan = plan
        logger.info("User testing begun")

    def schedule_user_testing(self, date: datetime.date):
        """As a UI designer, schedule user testing."""
        self.user_testing_schedule = date
        logger.info(f"User testing scheduled for {date}")

    def design_ui_schedule(self, timeline: Dict):
        """As an Owner, design schedule from UI SME."""
        self.ui_timeline = timeline
        logger.info("UI improvement schedule designed")

    def design_ui_audit(self, scope: Dict):
        """As an Owner, design audit from UI SME."""
        self.ui_audit_scope = scope
        logger.info("UI improvement audit designed")

    def prevent_double_publishing_fabs(self, submission_id: str):
        """As a Developer, prevent double publishing after refresh."""
        if submission_id in self.submissions and self.submissions[submission_id].status == PublishStatus.PUBLISHED:
            raise ValueError("Already published - preventing duplicate")
        else:
            self.publish_fabs_submission(submission_id)

    def publish_fabs_submission(self, submission_id: str):
        """Publish FABS submission."""
        if submission_id in self.submissions:
            self.submissions[submission_id].status = PublishStatus.PUBLISHED
            logger.info(f"Published {submission_id}")

    def receive_fabs_updates(self, updates: List[Dict]):
        """As a data user, receive updates to FABS records."""
        for update in updates:
            sub_id = update.get('id')
            if sub_id in self.submissions:
                self.submissions[sub_id].data.update(update)
                self.submissions[sub_id].updated_at = datetime.datetime.now()

    def update_fabs_sample_file_remove_funding_agency_code(self):
        """As a Developer, update FABS sample file to remove FundingAgencyCode header."""
        self.sample_file_headers.remove('FundingAgencyCode')
        logger.info("Updated FABS sample file - removed FundingAgencyCode")

    def ensure_deleted_fsrs_records_excluded(self, records: List[Dict]):
        """As an agency user, ensure deleted FSRS records not included."""
        active_records = [r for r in records if r.get('status') != 'deleted']
        return active_records

    def update_financial_assistance_daily(self):
        """As a website user, see updated financial assistance data daily."""
        today = datetime.date.today()
        self.last_update = today
        logger.info(f"Updated financial data on {today}")

    def deactivate_publish_button_during_derivations(self, submission_id: str):
        """As a user, deactivate publish button while derivations happen."""
        self.submissions[submission_id].status = PublishStatus.DRAFT  # Simulate lock
        self.derive_fields(submission_id)
        self.submissions[submission_id].status = PublishStatus.PUBLISHED  # Unlock after

    def derive_fields(self, submission_id: str):
        """Derive fields for submission."""
        if submission_id in self.submissions:
            data = self.submissions[submission_id].data
            data['derived_frec'] = f"{data.get('agency', '')}_derived"
            logger.info(f"Derived fields for {submission_id}")

    def prevent_non_existent_record_operations(self, record_id: str, operation: str):
        """As a Developer, ensure attempts on non-existent records don't create data."""
        if record_id not in self.submissions:
            logger.warning(f"Non-existent record {record_id} - {operation} prevented")
            return False
        return True

    def reset_environment_staging_max(self):
        """As an Owner, reset environment to Staging MAX permissions."""
        self.permissions = "staging_max"
        logger.info("Environment reset to Staging MAX permissions")

    def include_flexfields_in_error_files(self, submission: Submission, missing_required: str):
        """As a user, include flexfields in warning/error files when missing required."""
        submission.warnings.append(f"Missing {missing_required} - flexfields: {self.flexfields}")
        logger.info("Flexfields included in error files")

    def ensure_accurate_ppop_data(self, data: Dict):
        """As a user, accurate data for PPoPCode and PPoPCongressionalDistrict."""
        data['PPoPCode'] = data.get('PPoPCode', 'default')
        data['PPoPCongressionalDistrict'] = data.get('PPoPCongressionalDistrict', '01')
        return data

    def accept_zero_blank_for_loan_records(self, value: str, is_loan: bool):
        """As an agency user, accept zero/blank for loan records in validations."""
        if is_loan and (value == '0' or value == ''):
            return True
        return bool(value)

    def deploy_fabs_to_production(self):
        """As an Agency user, deploy FABS to production."""
        self.deployment['fabs'] = 'production'
        logger.info("FABS deployed to production")

    def clarify_cfda_error_triggers(self, error_code: str):
        """As a Developer, clarify CFDA error code triggers."""
        triggers = {
            ValidationRule.CFDA_ERROR: "Triggered when CFDA title mismatches or missing"
        }
        return triggers.get(error_code, "Unknown")

    def ensure_complete_sam_data(self, sam_data: Dict):
        """As an agency user, confident in complete SAM data."""
        required_fields = ['duns', 'name', 'address']
        for field in required_fields:
            if field not in sam_data:
                sam_data[field] = 'default_complete'
        return sam_data

    def index_domain_models(self):
        """As a Developer, index models for faster validation."""
        # Simulate indexing
        self.indexed_models = True
        logger.info("Domain models indexed for performance")

    def accept_zero_blank_non_loan(self, value: str, is_loan: bool):
        """As an agency user, accept zero/blank for non-loan records."""
        if not is_loan and (value == '0' or value == ''):
            return True
        return bool(value)

    def update_sql_codes_for_clarity(self, sql: str):
        """As a broker team member, update SQL for clarity."""
        # Simulate update
        self.sql_codes['clarified'] = sql.replace('SELECT *', 'SELECT explicit_columns')
        logger.info("SQL codes updated for clarity")

    def derive_all_data_elements(self, data: Dict):
        """As an agency user, ensure all derived elements proper."""
        derived = {
            'frec': data.get('agency') + '_frec',
            'office_name': self.derive_office_name(data.get('office_code'))
        }
        data.update(derived)
        return data

    def derive_office_name(self, code: str) -> str:
        """Derive office name from code."""
        names = {'001': 'Office of Finance'}
        return names.get(code, 'Unknown Office')

    def add_00_ppopcode_cases(self, data: Dict):
        """As a broker team member, add 00***** and 00FORGN PPoPCode to derivation."""
        ppop = data.get('PPoPCode', '')
        if re.match(r'^00\*{4,5}$', ppop) or ppop == '00FORGN':
            data['PPoPCode_derived'] = 'Foreign or Special'
        return data

    def derive_office_names_from_codes(self, codes: List[str]):
        """As a data user, see office names derived."""
        names = [self.derive_office_name(code) for code in codes]
        return names

    def historical_fabs_loader_derive_fields(self, historical_data: List[Dict]):
        """As a broker user, derive fields in historical FABS loader."""
        for record in historical_data:
            record['agency_code_correct'] = record.get('agency', 'default')
            self.derive_fields_for_record(record)
        self.historical_data.update({r['id']: r for r in historical_data})

    def derive_fields_for_record(self, record: Dict):
        """Derive for single record."""
        record['frec_derived'] = record.get('frec', 'derived_value')

    def update_broker_resources_for_launch(self, updates: Dict):
        """As a broker team member, update resources for FABS and DAIMS v1.1 launch."""
        self.resources.update(updates)
        logger.info("Broker resources updated for launch")

    def load_historical_fabs_include_frec(self, data: List[Dict]):
        """As a Developer, load historical FABS with FREC derivations."""
        self.historical_fabs_loader_derive_fields(data)
        logger.info("Historical FABS loaded with FREC")

    def prevent_nasa_grants_as_contracts(self, records: List[Dict]):
        """As a user, don't see NASA grants as contracts."""
        filtered = [r for r in records if not (r.get('agency') == 'NASA' and r.get('type') == 'grant')]
        return filtered

    def duns_validation_accept_bcd(self, record: Dict):
        """As a user, DUNS validation accept B,C,D ActionTypes if registered in SAM."""
        action_type = record.get('ActionType')
        duns = record.get('DUNS')
        if action_type in ['B', 'C', 'D'] and self.is_duns_registered(duns):
            return True
        return False

    def is_duns_registered(self, duns: str) -> bool:
        """Check if DUNS registered."""
        return duns in ['123456789', '987654321']  # Simulated

    def duns_validation_accept_past_dates(self, record: Dict, sam_reg: Dict):
        """As a user, accept ActionDates before current but after initial reg."""
        action_date = datetime.datetime.strptime(record.get('ActionDate'), '%Y-%m-%d').date()
        initial_reg = sam_reg.get('initial_date')
        current_reg = sam_reg.get('current_date')
        if initial_reg <= action_date <= current_reg:
            return True
        return False

    def derive_funding_agency_code(self, data: Dict):
        """As a broker team member, derive FundingAgencyCode."""
        data['FundingAgencyCode'] = data.get('AwardingAgencyCode', 'derived')
        return data

    def update_legal_entity_address_line3_length(self, schema_version: str):
        """As an agency user, max length for LegalEntityAddressLine3 matches v1.1."""
        if schema_version == '1.1':
            self.max_lengths['LegalEntityAddressLine3'] = 100
        logger.info("Updated length for LegalEntityAddressLine3")

    def use_schema_v1_1_headers(self, headers: List[str]):
        """As an agency user, use schema v1.1 headers."""
        self.fabs_headers = ['ID', 'ActionDate', ...]  # v1.1 headers
        return self.fabs_headers

    def map_federal_action_obligation_to_atom_feed(self, obligation: str):
        """As a agency user, map FederalActionObligation to Atom Feed."""
        atom_map = {'obligation': obligation}
        return atom_map

    def ppop_zip_validation_like_legal_entity(self, zip_code: str):
        """As a Broker user, PPoPZIP+4 same as Legal Entity ZIP."""
        pattern = re.compile(r'^\d{5}(-\d{4})?$')
        return bool(pattern.match(zip_code))

    def link_sample_file_in_dialog(self):
        """As a FABS user, link SAMPLE FILE to correct file."""
        self.dialog_links['sample'] = self.sample_file_url
        logger.info("Sample file link updated in dialog")

    def update_fpds_data_daily(self):
        """As an Agency user, FPDS data up-to-date daily."""
        self.fpds_last_update = datetime.date.today()
        logger.info("FPDS data updated daily")

    def determine_d_files_generation_from_fabs_fpds(self):
        """As a Developer, determine how agencies generate/validate D Files."""
        process = "Validate FABS + FPDS -> Generate D1/D2"
        return process

    def generate_validate_d_files(self, fabs_data: Dict, fpds_data: Dict):
        """As a user, generate and validate D Files from FABS and FPDS."""
        combined = {**fabs_data, **fpds_data}
        errors = self.validate_file(combined)
        if not errors:
            self.generate_d_file(combined)
        return errors

    def show_header_updated_datetime(self):
        """As an Agency user, header shows date AND time."""
        now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.header_info['updated'] = now
        return now

    def helpful_file_level_error_wrong_extension(self, file_path: str):
        """As an Agency user, more helpful error for wrong extension."""
        ext = os.path.splitext(file_path)[1]
        if ext != '.csv':
            raise ValueError(f"Invalid extension {ext}. Expected .csv or .txt")

    def access_test_features_other_envs(self, env: str, feature: str):
        """As a tester, access test features in non-Staging envs."""
        if env != 'staging':
            self.test_features[feature] = True
            logger.info(f"Test feature {feature} enabled in {env}")

    def fabs_submission_errors_accurate(self, submission: Submission):
        """As a FABS user, errors accurately represent FABS errors."""
        submission.errors = [e for e in submission.errors if 'fabs' in e.lower()]
        return submission.errors

    def update_frontend_urls(self, old_url: str, new_url: str):
        """As a FABS user, frontend URLs reflect page accurately."""
        self.url_map[old_url] = new_url
        logger.info(f"URL updated: {old_url} -> {new_url}")

    def load_all_historical_financial_assistance(self):
        """As an Agency user, load all historical FA data for FABS go-live."""
        self.historical_fa_loaded = True
        logger.info("All historical Financial Assistance data loaded")

    def load_historical_fpds_both_sources(self):
        """As a Developer, load historical FPDS from extracted and feed."""
        self.historical_fpds['sources'] = ['extracted', 'feed']
        logger.info("Historical FPDS loaded from both sources")

    def load_historical_fpds(self):
        """As an Agency user, historical FPDS loaded."""
        self.load_historical_fpds_both_sources()

    def show_submission_creator(self, submission_id: str):
        """As an Agency user, see who created submission."""
        if submission_id in self.submissions:
            return self.submissions[submission_id].created_by
        return "Unknown"

    def get_file_f_correct_format(self):
        """As an agency user, get File F in correct format."""
        file_f = {"format": "v1.1", "structure": "correct"}
        return json.dumps(file_f)

    def better_file_level_errors(self, errors: List[str]):
        """As an Agency user, better understand file-level errors."""
        detailed = [f"Detailed: {e}" for e in errors]
        return detailed

    def provide_fabs_groups_frec_paradigm(self):
        """As a Developer, provide FABS groups under FREC."""
        self.fabs_groups['frec'] = ['group1', 'group2']
        logger.info("FABS groups provided under FREC")

    def test_fabs_derivations_robust(self, test_file: str):
        """As a tester, ensure FABS derives properly with robust test."""
        self.derive_fields(test_file)  # Simulate
        # Follow-up check
        if 'derived' in self.submissions.get(test_file, {}).data:
            logger.info("Derivations test passed")
        else:
            logger.warning("Derivations test failed")

    def only_zero_padded_fields(self, data: Dict):
        """As an owner, only zero-padded fields."""
        for key, value in data.items():
            if isinstance(value, str) and re.match(r'^\d+$', value):
                data[key] = value.zfill(10)
        return data

    def submit_individual_recipients_no_duns_error(self, records: List[Dict]):
        """As a Broker user, submit individual recipients without DUNS error."""
        for record in records:
            if record.get('recipient_type') == 'individual':
                record['DUNS'] = 'INDIVIDUAL'
                # Skip DUNS validation
        return records

    def show_publish_row_count_before_decision(self, submission_id: str):
        """As a user, more info on rows to publish."""
        rows = len(self.submissions[submission_id].data.get('rows', []))
        logger.info(f"Rows to publish: {rows}")
        return rows

    def prevent_duplicate_transactions_time_gap(self, submission_id: str):
        """As a Developer, prevent duplicates during validation-publish gap."""
        self.prevent_double_publishing_fabs(submission_id)
        # Simulate time gap handling
        import time
        time.sleep(1)  # Gap

    def submit_citywide_ppopzip(self, zip_code: str):
        """As a FABS user, submit citywide PPoPZIP without error."""
        if 'citywide' in zip_code.lower():
            return True  # Pass validation
        return self.ppop_zip_validation_like_legal_entity(zip_code)

    def updated_error_codes_detailed(self, error: str):
        """As a Broker user, updated error codes with info."""
        detailed_errors = {
            'DUNS_ERROR': 'DUNS missing or invalid - check SAM registration',
            # More
        }
        return detailed_errors.get(error, error)

    def leave_off_last_4_zip_no_error(self, zip5: str):
        """As an agency user, leave off last 4 digits ZIP no error."""
        if len(zip5) == 5 and re.match(r'^\d{5}$', zip5):
            return True
        return False

    def historical_data_all_columns(self):
        """As a FABS user, historical data includes all columns."""
        required_cols = ['ID', 'ActionDate', 'Amount']
        self.historical_columns = required_cols
        logger.info("Historical data columns ensured")

    def access_additional_fpds_fields(self, fields: List[str]):
        """As a data user, access two additional FPDS fields."""
        self.fpds_additional_fields = fields[:2]
        return fields[:2]

    def additional_submission_dashboard_info(self, info: Dict):
        """As a FABS user, additional helpful info in dashboard."""
        self.dashboard_info.update(info)
        logger.info("Dashboard info updated")

    def download_uploaded_fabs_file(self, file_name: str):
        """As a FABS user, download uploaded FABS file."""
        if os.path.exists(file_name):
            return file_name  # Simulate download path
        return None

    def quick_access_broker_data(self, query: str):
        """As a Developer, quick access to Broker data."""
        result = {k: v for k, v in self.submissions.items() if query in k}
        return result

    def load_historical_fpds_since_2007(self):
        """As a Developer, load historical FPDS since 2007."""
        start = datetime.date(2007, 1, 1)
        self.historical_fpds['since'] = start
        logger.info("Historical FPDS loaded since 2007")

    def update_fabs_language(self, new_text: str):
        """As a FABS user, appropriate language on FABS pages."""
        self.fabs_text = new_text
        logger.info("FABS language updated")

    def separate_banners_dabs_fabs(self, app: str):
        """As a FABS user, no DABS banners in FABS and vice versa."""
        self.banners[app] = app.upper()
        logger.info(f"Banners separated for {app}")

    def fabs_read_only_dabs(self):
        """As a FABS user, read-only access to DABS."""
        self.permissions['fabs_dabs'] = 'read_only_dabs'
        logger.info("Read-only DABS access for FABS users")

    def run_validations_reasonable_time(self, file_path: str):
        """As a FABS user, validations in reasonable time."""
        start = datetime.datetime.now()
        errors = self.validate_file(file_path)
        end = datetime.datetime.now()
        duration = (end - start).total_seconds()
        if duration > 30:
            logger.warning("Validation took too long")
        return errors

    def validate_file(self, file_path_or_data) -> List[str]:
        """Generic validation."""
        return ['Validation error'] if 'error' in str(file_path_or_data) else []

    def correct_status_labels_dashboard(self, submission: Submission):
        """As a FABS user, correct status labels on dashboard."""
        labels = {PublishStatus.DRAFT: 'Draft', PublishStatus.PUBLISHED: 'Published'}
        submission.data['status_label'] = labels.get(submission.status)
        return submission

    def show_submission_periods(self):
        """As an agency user, know submission periods start/end."""
        periods = self.submission_periods
        return [(p[0].strftime('%Y-%m-%d'), p[1].strftime('%Y-%m-%d')) for p in periods]

    def landing_page_navigate_fabs_dabs(self):
        """As an agency user, landing page to FABS or DABS."""
        self.landing_page['nav'] = ['FABS', 'DABS']
        logger.info("Landing page navigation added")

    def submit_data_with_quotes_preserve_zeroes(self, data: List[str]):
        """As an agency user, submit data in quotes to preserve zeroes."""
        quoted = [f'"{d}"' if isinstance(d, str) and re.match(r'^\d+$', d) else d for d in data]
        return quoted

    # Additional methods for completeness
    def receive_fabs_updates_duplicate(self, updates: List[Dict]):
        """Duplicate story - receive updates."""
        self.receive_fabs_updates(updates)

    def handle_large_flexfields_duplicate(self, flexfields: List[str]):
        """Duplicate story."""
        self.handle_large_flexfields_without_impact(flexfields)

    def access_raw_agency_files_duplicate(self, agency: str):
        """Duplicate."""
        self.access_raw_agency_published_fabs_files(agency)

    # Initialize app
    def __init__(self):
        super().__init__()  # If subclass, but here it's the class
        self.landing_edits = {'round': 1}
        self.homepage_edits = {'round': 1}
        self.help_edits = {'round': 1}
        self.resources_style = "old"
        self.resources = {}
        self.mockups = {}
        self.tech_thursday_issues = []
        self.testing_summary = ""
        self.user_testing_active = False
        self.user_testing_plan = {}
        self.user_testing_schedule = None
        self.ui_timeline = {}
        self.ui_audit_scope = {}
        self.d_files_cache = {}
        self.sample_file_headers = ['ID', 'FundingAgencyCode']  # Initial, to be removed
        self.deployment = {}
        self.max_lengths = {}
        self.fabs_headers = []
        self.dialog_links = {}
        self.fpds_last_update = None
        self.url_map = {}
        self.historical_fa_loaded = False
        self.historical_fpds = {}
        self.dashboard_info = {}
        self.test_features = {}
        self.fabs_groups = {}
        self.historical_columns = []
        self.fpds_additional_fields = []
        self.fabs_text = ""
        self.banners = {}
        self.permissions = {}
        self.d_files_cache = {}
        self.indexed_models = False
        self.sql_codes = {}
        self.submission_periods = self.submission_periods  # Already set

if __name__ == "__main__":
    app = BrokerApp()
    # Simulate some usage
    sub = Submission("test1", "test.csv", PublishStatus.DRAFT, "user1", datetime.datetime.now(), datetime.datetime.now(), {"rows": [1,2]})
    app.submissions["test1"] = sub
    app.update_fabs_submission_on_status_change("test1", PublishStatus.PUBLISHED)
    app.enhanced_logging("Test log", "test1")
    print("BrokerApp initialized and basic functions tested.")</pre>
      </div>

      <h2>Confidence & Basic Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Total completion tokens</th>
            <td>7713</td>
          </tr>
          <tr>
            <th>Total log-probability</th>
            <td>-799.518</td>
          </tr>
          <tr>
            <th>Average per-token probability</th>
            <td>90.15%</td>
          </tr>
          <tr>
            <th>Perplexity</th>
            <td>1.11</td>
          </tr>
        </table>
      </div>

      <h2>Code Structure & Length Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Function count (AST)</th>
            <td>0</td>
          </tr>
          <tr>
            <th>Class count (AST)</th>
            <td>0</td>
          </tr>
          <tr>
            <th>Number of lines</th>
            <td>727</td>
          </tr>
          <tr>
            <th>Non-empty lines</th>
            <td>613</td>
          </tr>
          <tr>
            <th>Avg line length (all lines, chars)</th>
            <td>
              43.2
            </td>
          </tr>
          <tr>
            <th>Avg line length (non-empty, chars)</th>
            <td>
              51.2
            </td>
          </tr>
          <tr>
            <th>Avg tokens per non-empty line</th>
            <td>
              4.71
            </td>
          </tr>
          <tr>
            <th>AST depth (max nesting)</th>
            <td>0</td>
          </tr>
          <tr>
            <th>Import count</th>
            <td>0</td>
          </tr>
          <tr>
            <th>Import names</th>
            <td></td>
          </tr>
          <tr>
            <th>Avg cyclomatic complexity (functions)</th>
            <td>
              0.00
            </td>
          </tr>
          <tr>
            <th>Max cyclomatic complexity (functions)</th>
            <td>0.0</td>
          </tr>
          <tr>
            <th>Module cyclomatic complexity</th>
            <td>0.0</td>
          </tr>
          <tr>
            <th>Average function size (lines)</th>
            <td>
              0.0
            </td>
          </tr>
          <tr>
            <th>Comment density (%)</th>
            <td>
              2.4%
            </td>
          </tr>
          <tr>
            <th>Import redundancy ratio</th>
            <td>
              0.00
            </td>
          </tr>
        </table>
      </div>

      <h2>Semantic Quality Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Syntax valid</th>
            <td>False</td>
          </tr>
          <tr>
            <th>Flake8 style errors</th>
            <td>1</td>
          </tr>
          <tr>
            <th>Flake8 errors (by category)</th>
            <td>
              <div class="nested-table">
                <table>
                  <tr>
                    <th>Style errors (PEP8 spacing, indentation, etc.) (E)</th>
                    <td>
                      1
                    </td>
                  </tr>
                  <tr>
                    <th>
                      Logical errors (undefined vars, unused imports, etc.) (F)
                    </th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Warnings (whitespace, etc.) (W)</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>McCabe complexity issues (C)</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Naming conventions (N)</th>
                    <td>
                      0
                    </td>
                  </tr>
                </table>
              </div>
            </td>
          </tr>
          <tr>
            <th>Mypy type-check errors</th>
            <td>1</td>
          </tr>
          <tr>
            <th>Mypy error breakdown</th>
            <td>
              <div class="nested-table">
                <table>
                  <tr>
                    <th>Return type</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Argument type</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Missing return</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Attribute</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Annotation</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>Other</th>
                    <td>
                      1
                    </td>
                  </tr>
                </table>
              </div>
            </td>
          </tr>
          <tr>
            <th>Semantic quality score (0–100)</th>
            <td>48.5</td>
          </tr>
        </table>
      </div>

      <h2>Execution-Based Metrics</h2>
      <div class="metrics">
        <table>
          <tr>
            <th>Execution success</th>
            <td>False</td>
          </tr>
          <tr>
            <th>Execution time (s)</th>
            <td>
              0.726
            </td>
          </tr>
          <tr>
            <th>Exception type</th>
            <td>RuntimeError</td>
          </tr>
          <tr>
            <th>Exception message</th>
            <td>File "/app/code.py", line 49
    self.gt as_window_open: bool = False
            ^^^^^^^^^^^^^^
SyntaxError: invalid syntax</td>
          </tr>
          <tr>
            <th>Runtime output (preview)</th>
            <td>
              <div class="runtime-output">
                <pre>File "/app/code.py", line 49
    self.gt as_window_open: bool = False
            ^^^^^^^^^^^^^^
SyntaxError: invalid syntax</pre>
              </div>
            </td>
          </tr>
        </table>
      </div>
      
      <h2>Total Credibility (0-100%)</h2>
      <p><b>Credibility:</b> 0.00%</p>

      <h2>Visualizations</h2>
      <div class="visualizations">
        <h3>Basic Confidence Metrics</h3>
        <img src="1_logprob_trend.png" alt="Log Probability Trend" />
        <img src="2_probability_distribution.png" alt="Probability Distribution" />
        <img src="3_cumulative_logprob.png" alt="Cumulative Log Probability" />
        
        <h3>Advanced Analysis</h3>
        <img src="4_smoothed_confidence.png" alt="Smoothed Confidence Trend" />
        <img src="5_uncertainty_heatmap.png" alt="Uncertainty Detection" />
        <img src="6_rolling_perplexity.png" alt="Rolling Perplexity" />
        
        <h3>Segmented Analysis</h3>
        <img src="7_confidence_by_segment.png" alt="Confidence by Segment" />
        <img src="8_confidence_by_token_type.png" alt="Confidence by Token Type" />
        <img src="9_confidence_volatility.png" alt="Confidence Volatility" />
        <img src="10_top_uncertain_tokens.png" alt="Top Uncertain Tokens" />
      </div>
    </div>
  </body>
</html>
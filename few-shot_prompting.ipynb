{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e881e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment and dependencies\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Google Gemini model\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1187d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot prompting is a technique where you provide a large language model with a few examples of the task you want it to perform, directly within the prompt itself. This helps the model understand the desired input-output format and underlying pattern, leading to better performance on new, similar tasks without requiring any model fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a simple message\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Explain few-shot prompting in a couple of short sentences.\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import components for few-shot prompting\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "print(\"Components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples created:\n",
      "1. Input: 'I love this movie! It's amazing!' → Output: 'Positive'\n",
      "2. Input: 'This food tastes terrible.' → Output: 'Negative'\n",
      "3. Input: 'The weather is okay today.' → Output: 'Neutral'\n",
      "4. Input: 'I'm so excited about my vacation!' → Output: 'Positive'\n",
      "5. Input: 'This service is disappointing.' → Output: 'Negative'\n"
     ]
    }
   ],
   "source": [
    "# Create examples for few-shot prompting\n",
    "# Examples for sentiment analysis\n",
    "examples = [\n",
    "    {\"input\": \"I love this movie! It's amazing!\", \"output\": \"Positive\"},\n",
    "    {\"input\": \"This food tastes terrible.\", \"output\": \"Negative\"},\n",
    "    {\"input\": \"The weather is okay today.\", \"output\": \"Neutral\"},\n",
    "    {\"input\": \"I'm so excited about my vacation!\", \"output\": \"Positive\"},\n",
    "    {\"input\": \"This service is disappointing.\", \"output\": \"Negative\"}\n",
    "]\n",
    "\n",
    "print(\"Examples created:\")\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"{i}. Input: '{example['input']}' → Output: '{example['output']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples formatted:\n",
      "Human: I love this movie! It's amazing!\n",
      "AI: Positive\n",
      "Human: This food tastes terrible.\n",
      "AI: Negative\n",
      "Human: The weather is okay today.\n",
      "AI: Neutral\n",
      "Human: I'm so excited about my vacation!\n",
      "AI: Positive\n",
      "Human: This service is disappointing.\n",
      "AI: Negative\n"
     ]
    }
   ],
   "source": [
    "# Create the few-shot prompt template\n",
    "# Define the example template\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Create the few-shot prompt template\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# Test the few-shot prompt\n",
    "formatted_examples = few_shot_prompt.format()\n",
    "print(\"Few-shot examples formatted:\")\n",
    "print(formatted_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete prompt template created!\n"
     ]
    }
   ],
   "source": [
    "# Create the complete prompt template with examples\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a sentiment analyzer. Classify the sentiment of the given text as Positive, Negative, or Neutral. Look at these examples:\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"Now classify this: {input}\")\n",
    "])\n",
    "\n",
    "print(\"Complete prompt template created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e02b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing few-shot prompting:\n",
      "========================================\n",
      "Input: 'This book is incredible!'\n",
      "Output: Positive\n",
      "--------------------\n",
      "Input: 'I hate waiting in long lines.'\n",
      "Output: Negative\n",
      "--------------------\n",
      "Input: 'The meeting was fine.'\n",
      "Output: Neutral\n",
      "--------------------\n",
      "Input: 'Best pizza I've ever had!'\n",
      "Output: Positive\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Create and test the few-shot chain\n",
    "# Create the chain\n",
    "sentiment_chain = final_prompt | model | parser\n",
    "\n",
    "# Test with new examples\n",
    "test_inputs = [\n",
    "    \"This book is incredible!\",\n",
    "    \"I hate waiting in long lines.\",\n",
    "    \"The meeting was fine.\",\n",
    "    \"Best pizza I've ever had!\"\n",
    "]\n",
    "\n",
    "print(\"Testing few-shot prompting:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for text in test_inputs:\n",
    "    result = sentiment_chain.invoke({\"input\": text})\n",
    "    print(f\"Input: '{text}'\")\n",
    "    print(f\"Output: {result}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13e881e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup environment and dependencies\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Set up LangSmith environment variables if not already set (optional)\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c866c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize Google Gemini model\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1187d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot prompting is a technique where a large language model (LLM) is provided with a small number of example input-output pairs directly within the prompt itself. These examples illustrate the desired task, format, or style the model should follow, effectively conditioning its immediate response without altering its underlying weights.\n",
      "\n",
      "By observing these few instances of a task—be it classification, summarization, or question answering—the LLM learns to infer the underlying pattern or instruction. This allows the model to generalize the demonstrated behavior to a new, unseen query, often resulting in significantly improved performance compared to zero-shot (no examples) or one-shot (a single example) prompting, without requiring extensive fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test the model with a simple message\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Explain few-shot prompting briefly, in a maximum of two short paragraphs.\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0856da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Import components for few-shot prompting\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "print(\"Components imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5a3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples created:\n",
      "1. Input: 'I love this movie! It's amazing!' → Output: 'Positive'\n",
      "2. Input: 'This food tastes terrible.' → Output: 'Negative'\n",
      "3. Input: 'The weather is okay today.' → Output: 'Neutral'\n",
      "4. Input: 'I'm so excited about my vacation!' → Output: 'Positive'\n",
      "5. Input: 'This service is disappointing.' → Output: 'Negative'\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create examples for few-shot prompting\n",
    "# Examples for sentiment analysis\n",
    "examples = [\n",
    "    {\"input\": \"I love this movie! It's amazing!\", \"output\": \"Positive\"},\n",
    "    {\"input\": \"This food tastes terrible.\", \"output\": \"Negative\"},\n",
    "    {\"input\": \"The weather is okay today.\", \"output\": \"Neutral\"},\n",
    "    {\"input\": \"I'm so excited about my vacation!\", \"output\": \"Positive\"},\n",
    "    {\"input\": \"This service is disappointing.\", \"output\": \"Negative\"}\n",
    "]\n",
    "\n",
    "print(\"Examples created:\")\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"{i}. Input: '{example['input']}' → Output: '{example['output']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e29c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot examples formatted:\n",
      "Human: I love this movie! It's amazing!\n",
      "AI: Positive\n",
      "Human: This food tastes terrible.\n",
      "AI: Negative\n",
      "Human: The weather is okay today.\n",
      "AI: Neutral\n",
      "Human: I'm so excited about my vacation!\n",
      "AI: Positive\n",
      "Human: This service is disappointing.\n",
      "AI: Negative\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create the few-shot prompt template\n",
    "# Define the example template\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Create the few-shot prompt template\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# Test the few-shot prompt\n",
    "formatted_examples = few_shot_prompt.format()\n",
    "print(\"Few-shot examples formatted:\")\n",
    "print(formatted_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e4aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete prompt template created!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Create the complete prompt template with examples\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a sentiment analyzer. Classify the sentiment of the given text as Positive, Negative, or Neutral. Look at these examples:\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"Now classify this: {input}\")\n",
    "])\n",
    "\n",
    "print(\"Complete prompt template created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e02b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing few-shot prompting:\n",
      "========================================\n",
      "Input: 'This book is incredible!'\n",
      "Output: Positive\n",
      "--------------------\n",
      "Input: 'I hate waiting in long lines.'\n",
      "Output: Negative\n",
      "--------------------\n",
      "Input: 'The meeting was fine.'\n",
      "Output: Neutral\n",
      "--------------------\n",
      "Input: 'Best pizza I've ever had!'\n",
      "Output: Positive\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create and test the few-shot chain\n",
    "# Create the chain\n",
    "sentiment_chain = final_prompt | model | parser\n",
    "\n",
    "# Test with new examples\n",
    "test_inputs = [\n",
    "    \"This book is incredible!\",\n",
    "    \"I hate waiting in long lines.\",\n",
    "    \"The meeting was fine.\",\n",
    "    \"Best pizza I've ever had!\"\n",
    "]\n",
    "\n",
    "print(\"Testing few-shot prompting:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for text in test_inputs:\n",
    "    result = sentiment_chain.invoke({\"input\": text})\n",
    "    print(f\"Input: '{text}'\")\n",
    "    print(f\"Output: {result}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

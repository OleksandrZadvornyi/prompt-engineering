{
    "model": "llama",
    "prompt_variant": "chain-of-thought-clusters",
    "embedding_model": "all-MiniLM-L6-v2",
    "scores": {
        "original_vs_iter1": 0.8629300594329834,
        "original_vs_iter2": 0.7745218873023987,
        "iter1_vs_iter2": 0.9290253520011902
    },
    "counts": {
        "original": 98,
        "iter1": 20,
        "iter2": 20
    }
}
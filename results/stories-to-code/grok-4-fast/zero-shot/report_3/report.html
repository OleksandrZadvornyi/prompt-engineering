
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analysis Report: Run 3</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f9f9f9;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: 20px auto;
            padding: 24px;
            background-color: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        h1, h2, h3 {
            color: #111;
            margin-top: 1.2em;
            margin-bottom: 0.6em;
        }
        h1 {
            font-size: 2em;
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
        }
        h2 {
            font-size: 1.5em;
            color: #555;
        }
        h3 {
            font-size: 1.2em;
            border-bottom: 1px solid #eee;
            padding-bottom: 5px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #f7f7f7;
            font-weight: 600;
            width: 30%;
        }
        td {
            background-color: #fff;
        }
        details {
            border: 1px solid #ddd;
            border-radius: 4px;
            margin-bottom: 10px;
            background-color: #fff;
        }
        summary {
            padding: 12px;
            font-weight: 600;
            cursor: pointer;
            background-color: #f7f7f7;
        }
        summary:hover {
            background-color: #eee;
        }
        pre {
            background-color: #fdfdfd;
            border-top: 1px solid #eee;
            padding: 15px;
            margin: 0;
            overflow-x: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
            font-size: 0.9em;
            line-height: 1.6;
        }
        code {
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
        }
        .credibility-score {
            font-size: 1.8em;
            font-weight: bold;
            color: #005fdd;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Analysis Report #3</h1>
        <h2>x-ai/grok-4-fast</h2>
        <p><strong>Prompt Variant:</strong> zero-shot</p>

        <h3>Total Credibility Score</h3>
        <p class="credibility-score">40.84%</p>

        
    <h3>Key Metrics</h3>
    <table>
        <tr><th>Perplexity</th><td>1.0949</td></tr>
<tr><th>Avg. Probability</th><td>0.9133</td></tr>
<tr><th>Total Tokens</th><td>9522</td></tr>

    </table>
    
        
    <h3>Execution Metrics</h3>
    <table>
        <tr><th>Execution Success</th><td>False</td></tr>
<tr><th>Execution Time Sec</th><td>1.0950</td></tr>
<tr><th>Exception Type</th><td>AttributeError</td></tr>
<tr><th>Exception Message</th><td>'sqlite3.Connection' object has no attribute 'rowcount'</td></tr>
<tr><th>Runtime Output</th><td>Traceback (most recent call last):
  File "/app/main.py", line 838, in <module>
    broker.process_2017_12_19_deletions([{'date': '2017-12-19', 'id': 1}])
  File "/app/main.py", line 87, in process_2017_12_19_deletions
    deleted_count += conn.rowcount
                     ^^^^^^^^^^^^^
AttributeError: 'sqlite3.Connection' object has no attribute 'rowcount'</td></tr>

    </table>
    
        
    <h3>Structural Metrics</h3>
    <table>
        <tr><th>Avg Cyclomatic Complexity</th><td>1.9881</td></tr>
<tr><th>Ast Depth</th><td>15</td></tr>
<tr><th>Avg Function Size Lines</th><td>7.6341</td></tr>
<tr><th>Import Redundancy Ratio</th><td>0.0000</td></tr>

    </table>
    
        
    <h3>Semantic Metrics</h3>
    <table>
        <tr><th>Syntax Valid</th><td>True</td></tr>
<tr><th>Flake8 Error Count</th><td>12</td></tr>
<tr><th>Mypy Error Count</th><td>5</td></tr>

    </table>
    

        <details>
            <summary>View Full Prompt</summary>
            <pre>Generate fully functional Python code that implements the following user stories. The code should realistically reflect the described functionality.

﻿As a Data user, I want to have the 12-19-2017 deletions processed.
As a UI designer, I want to redesign the Resources page, so that it matches the new Broker design styles.
As a UI designer, I want to report to the Agencies about user testing, so that they are aware of their contributions to making Broker a better UX.
As a UI designer, I want to move on to round 2 of DABS or FABS landing page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 3 of the Help page edits, so that I can get approvals from leadership.
As a Developer , I want to be able to log better, so that I can troubleshoot issues with particular submissions and functions.
As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes, so that I know when the status of the submission has changed.
As a DevOps engineer, I want New Relic to provide useful data across all applications.
As a UI designer,  I want to move on to round 2 of the Help page edits, so that I can get approvals from leadership.
As a UI designer, I want to move on to round 2 of Homepage edits, so that I can get approvals from leadership.
As a Broker user, I want to Upload and Validate the error message to have accurate text.
As a Broker user, I want the D1 file generation to be synced with the FPDS data load, so that I don&#x27;t have to regenerate a file if no data has been updated.
As a Website user, I want to access published FABS files, so that I can see the new files as they come in.
As an owner, I want to be sure that USAspending only send grant records to my system.
As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
As a Developer, I want to add the GTAS window data to the database, so that I can ensure the site is locked down during the GTAS submission period.
As a Developer, I want D Files generation requests to be managed and cached, so that duplicate requests do not cause performance issues.
As a user, I want to access the raw agency published files from FABS via USAspending.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Broker user, I want  to help create content mockups, so that I can submit my data efficiently.
As a UI designer, I want to track the issues that come up in Tech Thursday, so that I know what to test and what want s to be fixed.
As an Owner, I want to create a user testing summary from the UI SME, so that I can know what UI improvements we will follow through on.
As a UI designer, I want to begin user testing, so that I can validate stakeholder UI improvement requests.
As a UI designer, I want to schedule user testing, so that I can give the testers advanced notice to ensure buy-in.
As an Owner, I want to design a schedule from the UI SME, so that I know the potential timeline of the UI improvements wanted.
As an Owner, I want to design an audit from the UI SME, so that I know the potential scope of the UI improvements want ed.
As a Developer, I want to prevent users from double publishing FABS submissions after refreshing, so that there are no duplicates.
As an data user, I want to receive updates to FABS records.
As an Agency user, I want to be able to include a large number of flexfields without performance impact.
As a Developer , I want to update the FABS sample file to remove FundingAgencyCode after FABS is updated to no longer require the header.
As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
As a website user, I want to see updated financial assistance data daily.
As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening, so that I cannot click it multiple times for the same submission.
As a Developer , I want to ensure that attempts to correct or delete non-existent records don&#x27;t create new published data.
As an Owner, I want to reset the environment to only take Staging MAX permissions, so that I can ensure that the FABS testers no longer have access.
As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
As an Agency user, I want FABS deployed into production, so I can submit my Financial Assistance data.
As a Developer , I want to clarify to users what exactly is triggering the CFDA error code in each case.
As an agency user, I want to be confident that the data coming from SAM is complete.
As a Developer , I want my domain models to be indexed properly, so that I can get validation results back in a reasonable amount of time.
As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
As a broker team member, I want to make some updates to the SQL codes for clarity.
As an agency user, I want to have all derived data elements derived properly.
As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
As a data user, I want to see the office names derived from office codes, so that I can have appropriate context for understanding them.
As a broker user, I want the historical FABS loader to derive fields, so that my agency codes are correct in the PublishedAwardFinancialAssistance table.
As a broker team member, I want to ensure the Broker resources, validations, and P&amp;P pages are updated appropriately for the launch of FABS and DAIMS v1.1.
As a Developer, I want the data loaded from historical FABS to include the FREC derivations, so that I can have consistent FREC data for USASpending.gov.
As a user, I don&#x27;t want to see NASA grants displayed as contracts.
As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM, even though it may have expired.
As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
As a broker team member, I want to derive FundingAgencyCode, so that the data quality and completeness improves.
As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
As an agency user, I want to use the schema v1.1 headers in my FABS file.
As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
As a FABS user, I want to link the SAMPLE FILE on the &quot;What you want  to submit&quot; dialog to point to the correct file, so that I have an accurate reference for my agency submissions.
As an Agency user, I want FPDS data to be up-to-date daily.
As a user, I want to access the raw agency published files from FABS via USAspending.
As a Developer , I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
As a user, I want to generate and validate D Files from FABS and FPDS data.
As an Agency user, I want the header information box to show updated date AND time, so that I know when it was updated.
As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
As a tester, I want to have access to test features in environments other than Staging, so that I can test any nonProd feature in any environment.
As a FABS user, I want to submission errors to accurately represent FABS errors, so that I know why my submission didn&#x27;t work.
As a FABS user, I want the frontend URLs to more accurately reflect the page I&#x27;m accessing, so that I&#x27;m not confused.
As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
As a Developer , I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
As an Agency user, I want historical FPDS data loaded.
As an Agency user, I want to accurately see who created a submission, so that I&#x27;m not confused about who last updated a submission.
As an agency user, I want to get File F in the correct format.
As an Agency user, I want to better understand my file-level errors.
As a Developer , I want to provide FABS groups that function under the FREC paradigm.
As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
As an owner, I only want zero-padded fields, so that I can justify padding.
As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
As a user, I want more information about how many rows will be published prior to deciding whether to publish.
As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
As a Broker user, I want to have updated error codes that accurately reflect the logic and provide enough information, so that I can fix my submission.
As an agency user, I want to leave off the last 4 digits of the ZIP without an error, so that I can complete my submissions.
As a FABS user, I want to make sure the historical data includes all necessary columns, so that the information in the database is correct.
As a data user, I want to access two additional fields from the FPDS data pull.
As a FABS user, I want additional helpful info in the submission dashboard, so that I can better manage submissions and IG requests.
As a FABS user, I want to download the uploaded FABS file, so that I can get the uploaded file.
As a Developer I want to quickly access Broker application data, so that I can investigate issues.
As a Developer , I want to determine the best way to load historical FPDS data, so that I can load all FPDS data since 2007.
As a FABS user, I want the language on FABS pages to be appropriate for me, so that I am not confused.
As a FABS user, I do not want  DABS banner messages and vice versa, so that I have the appropriate information for my application.
As a FABS user, I want to have read-only access to DABS, so that I can view DABS pages without wanting two sets of permissions.
As a FABS user, I want to have my validations run in a reasonable amount of time.
As a FABS user, I want to see correct status labels on the Submission Dashboard, so that I can quickly see my submission history.
As an agency user, I want to know when the submission periods start and end, so that I know when the submission starts and ends.
As an agency user, I want a landing page to navigate to either FABS or DABS pages, so that I can access both sides of the site.
As an agency user, I want to submit my data elements surrounded by quotation marks, so that Excel won&#x27;t strip off leading and trailing zeroes.

Output only Python code (no markdown formatting or extra text). Do not leave functions empty — implement reasonable logic where needed.</pre>
        </details>
        
        <details>
            <summary>View Generated Code</summary>
            <pre><code>import logging
import json
import datetime
import hashlib
from typing import Dict, List, Optional, Any
from enum import Enum
import os
import sqlite3
from contextlib import contextmanager

# Configure logging for better troubleshooting
logging.basicConfig(level=logging.INFO, format=&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;)
logger = logging.getLogger(__name__)

class SubmissionStatus(Enum):
    DRAFT = &quot;draft&quot;
    PUBLISHED = &quot;published&quot;
    VALIDATING = &quot;validating&quot;
    ERROR = &quot;error&quot;

class BrokerSystem:
    def __init__(self, db_path: str = &quot;:memory:&quot;):
        self.db_path = db_path
        self.init_db()
        self.cache = {}
        self.flexfields_cache = {}
        self.submission_counter = 0

    def init_db(self):
        &quot;&quot;&quot;Initialize SQLite database for submissions, historical data, etc.&quot;&quot;&quot;
        with self.get_connection() as conn:
            conn.execute(&quot;&quot;&quot;
                CREATE TABLE IF NOT EXISTS submissions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT,
                    file_content TEXT,
                    status TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    publish_status TEXT DEFAULT &#x27;draft&#x27;,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            &quot;&quot;&quot;)
            conn.execute(&quot;&quot;&quot;
                CREATE TABLE IF NOT EXISTS historical_fabs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    record_data TEXT,
                    frec_derivations TEXT,
                    agency_code TEXT,
                    loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            &quot;&quot;&quot;)
            conn.execute(&quot;&quot;&quot;
                CREATE TABLE IF NOT EXISTS validations (
                    submission_id INTEGER,
                    rule_name TEXT,
                    is_valid BOOLEAN,
                    error_message TEXT,
                    FOREIGN KEY (submission_id) REFERENCES submissions (id)
                )
            &quot;&quot;&quot;)
            conn.execute(&quot;&quot;&quot;
                CREATE TABLE IF NOT EXISTS gtas_windows (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    start_date DATE,
                    end_date DATE,
                    is_locked BOOLEAN DEFAULT FALSE
                )
            &quot;&quot;&quot;)
            conn.commit()

    @contextmanager
    def get_connection(self):
        conn = sqlite3.connect(self.db_path)
        try:
            yield conn
        finally:
            conn.close()

    # As a Data user, I want to have the 12-19-2017 deletions processed.
    def process_2017_12_19_deletions(self, records_to_delete: List[Dict]):
        &quot;&quot;&quot;Process deletions for records dated 12-19-2017.&quot;&quot;&quot;
        deleted_count = 0
        for record in records_to_delete:
            if record.get(&#x27;date&#x27;) == &#x27;2017-12-19&#x27;:
                with self.get_connection() as conn:
                    conn.execute(&quot;DELETE FROM historical_fabs WHERE record_data LIKE ?&quot;, (f&quot;%{json.dumps(record)}%&quot;,))
                    deleted_count += conn.rowcount
                logger.info(f&quot;Deleted record: {record}&quot;)
        logger.info(f&quot;Processed {deleted_count} deletions for 12-19-2017.&quot;)

    # As a Developer, I want to be able to log better, so that I can troubleshoot issues.
    # Logging is already configured globally.

    # As a Developer, I want to add the updates on a FABS submission to be modified when the publishStatus changes.
    def update_submission_on_status_change(self, submission_id: int, new_status: str):
        &quot;&quot;&quot;Update submission when publishStatus changes.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT * FROM submissions WHERE id = ?&quot;, (submission_id,))
            row = cursor.fetchone()
            if row:
                old_status = row[3]
                if old_status != new_status:
                    conn.execute(&quot;&quot;&quot;
                        UPDATE submissions SET publish_status = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE id = ?
                    &quot;&quot;&quot;, (new_status, submission_id))
                    logger.info(f&quot;Status changed for submission {submission_id}: {old_status} -&gt; {new_status}&quot;)
                    conn.commit()
                    return True
        return False

    # As a DevOps engineer, I want New Relic to provide useful data across all applications.
    # Simulated with enhanced logging.
    def log_new_relic_metric(self, app_name: str, metric: Dict):
        logger.info(f&quot;New Relic metric for {app_name}: {json.dumps(metric)}&quot;)

    # As a Developer, I want to update the Broker validation rule table to account for the rule updates in DB-2213.
    def update_validation_rules(self, new_rules: List[Dict]):
        &quot;&quot;&quot;Update validation rules table with DB-2213 changes.&quot;&quot;&quot;
        with self.get_connection() as conn:
            for rule in new_rules:
                conn.execute(&quot;&quot;&quot;
                    INSERT OR REPLACE INTO validations (submission_id, rule_name, is_valid, error_message)
                    VALUES (?, ?, ?, ?)
                &quot;&quot;&quot;, (rule.get(&#x27;submission_id&#x27;, 0), rule[&#x27;name&#x27;], rule.get(&#x27;valid&#x27;, True), rule.get(&#x27;message&#x27;, &#x27;&#x27;)))
            conn.commit()
        logger.info(f&quot;Updated validation rules for DB-2213: {len(new_rules)} rules.&quot;)

    # As a Developer, I want to add the GTAS window data to the database.
    def add_gtas_window(self, start_date: str, end_date: str, is_locked: bool = False):
        &quot;&quot;&quot;Add GTAS submission window to lock site if needed.&quot;&quot;&quot;
        with self.get_connection() as conn:
            conn.execute(&quot;&quot;&quot;
                INSERT INTO gtas_windows (start_date, end_date, is_locked)
                VALUES (?, ?, ?)
            &quot;&quot;&quot;, (start_date, end_date, is_locked))
            conn.commit()
            logger.info(f&quot;Added GTAS window: {start_date} to {end_date}, locked: {is_locked}&quot;)
        # Simulate lockdown
        if is_locked:
            self.lock_site_during_gtas()

    def lock_site_during_gtas(self):
        &quot;&quot;&quot;Simulate site lockdown during GTAS period.&quot;&quot;&quot;
        logger.warning(&quot;Site locked down for GTAS submission period.&quot;)

    # As a Developer, I want D Files generation requests to be managed and cached.
    def generate_d_file(self, fabs_data: Dict, fpds_data: Dict, cache_key: Optional[str] = None) -&gt; str:
        &quot;&quot;&quot;Generate D file with caching to avoid duplicates.&quot;&quot;&quot;
        if cache_key:
            cache_hash = hashlib.md5(json.dumps((fabs_data, fpds_data)).encode()).hexdigest()
            if cache_hash in self.cache:
                logger.info(&quot;Using cached D file.&quot;)
                return self.cache[cache_hash]
        
        # Simulate generation
        d_file_content = {
            &#x27;fabs&#x27;: fabs_data,
            &#x27;fpds&#x27;: fpds_data,
            &#x27;generated_at&#x27;: datetime.datetime.now().isoformat(),
            &#x27;status&#x27;: &#x27;synced&#x27;
        }
        content_str = json.dumps(d_file_content)
        
        if cache_key:
            self.cache[cache_hash] = content_str
            logger.info(&quot;Cached D file generation.&quot;)
        
        return content_str

    # As a user, I want to access the raw agency published files from FABS via USAspending.
    def get_raw_fabs_file(self, agency_id: str, submission_id: int) -&gt; Optional[str]:
        &quot;&quot;&quot;Retrieve raw published FABS file.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;&quot;&quot;
                SELECT file_content FROM submissions
                WHERE user_id LIKE ? AND id = ? AND status = ?
            &quot;&quot;&quot;, (f&quot;%{agency_id}%&quot;, submission_id, SubmissionStatus.PUBLISHED.value))
            row = cursor.fetchone()
            if row:
                return row[0]
        logger.warning(f&quot;No raw file found for agency {agency_id}, submission {submission_id}&quot;)
        return None

    # As an Agency user, I want to be able to include a large number of flexfields without performance impact.
    def process_flexfields(self, flexfields: Dict, submission_id: int) -&gt; bool:
        &quot;&quot;&quot;Process large flexfields with caching.&quot;&quot;&quot;
        cache_key = f&quot;flex_{submission_id}&quot;
        if cache_key in self.flexfields_cache:
            logger.info(&quot;Using cached flexfields.&quot;)
            return True
        
        # Simulate processing without performance hit (batched)
        processed = {k: v for k, v in flexfields.items() if len(str(v)) &lt;= 1000}  # Reasonable limit
        self.flexfields_cache[cache_key] = processed
        logger.info(f&quot;Processed {len(processed)} flexfields for submission {submission_id}&quot;)
        return len(processed) == len(flexfields)

    # As a Broker user, I want to help create content mockups.
    def create_content_mockup(self, data: Dict) -&gt; str:
        &quot;&quot;&quot;Generate mockup for efficient data submission.&quot;&quot;&quot;
        mockup = f&quot;Mockup for {data.get(&#x27;agency&#x27;, &#x27;Unknown&#x27;)}: {json.dumps(data, indent=2)}&quot;
        logger.info(mockup)
        return mockup

    # As a UI designer, I want to track the issues that come up in Tech Thursday.
    # Simulated with a log tracker.
    def track_tech_thursday_issues(self, issues: List[str]):
        &quot;&quot;&quot;Track and log issues for testing and fixes.&quot;&quot;&quot;
        for issue in issues:
            logger.error(f&quot;Tech Thursday Issue: {issue}&quot;)
        self.issues_to_fix = issues  # Instance var for tracking

    # As a Developer, I want to prevent users from double publishing FABS submissions after refreshing.
    def publish_submission(self, submission_id: int, prevent_duplicate: bool = True) -&gt; bool:
        &quot;&quot;&quot;Publish with duplicate prevention.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT status FROM submissions WHERE id = ?&quot;, (submission_id,))
            row = cursor.fetchone()
            if row and row[0] == SubmissionStatus.PUBLISHED.value:
                if prevent_duplicate:
                    logger.warning(f&quot;Duplicate publish attempt prevented for {submission_id}&quot;)
                    return False
            conn.execute(&quot;&quot;&quot;
                UPDATE submissions SET status = ?, publish_status = ?
                WHERE id = ?
            &quot;&quot;&quot;, (SubmissionStatus.PUBLISHED.value, SubmissionStatus.PUBLISHED.value, submission_id))
            conn.commit()
            self.submission_counter += 1
            logger.info(f&quot;Published submission {submission_id}. Total: {self.submission_counter}&quot;)
            return True

    # As a data user, I want to receive updates to FABS records.
    def update_fabs_records(self, updates: List[Dict]):
        &quot;&quot;&quot;Apply updates to FABS records.&quot;&quot;&quot;
        updated = 0
        for update in updates:
            with self.get_connection() as conn:
                conn.execute(&quot;&quot;&quot;
                    UPDATE historical_fabs SET record_data = ?
                    WHERE id = ?
                &quot;&quot;&quot;, (json.dumps(update), update.get(&#x27;id&#x27;)))
                updated += conn.rowcount
            logger.info(f&quot;Updated FABS record: {update.get(&#x27;id&#x27;)}&quot;)
        logger.info(f&quot;Applied {updated} FABS updates.&quot;)

    # As a Developer, I want to update the FABS sample file to remove FundingAgencyCode.
    def generate_sample_file(self, include_funding_agency: bool = False) -&gt; Dict:
        &quot;&quot;&quot;Generate sample FABS file without FundingAgencyCode header.&quot;&quot;&quot;
        sample = {
            &#x27;headers&#x27;: [&#x27;ActionDate&#x27;, &#x27;UniqueAwardID&#x27;, &#x27;AwardAmount&#x27;],
            &#x27;rows&#x27;: [
                {&#x27;ActionDate&#x27;: &#x27;2023-01-01&#x27;, &#x27;UniqueAwardID&#x27;: &#x27;123&#x27;, &#x27;AwardAmount&#x27;: &#x27;1000&#x27;}
            ]
        }
        if not include_funding_agency:
            if &#x27;FundingAgencyCode&#x27; in sample[&#x27;headers&#x27;]:
                sample[&#x27;headers&#x27;].remove(&#x27;FundingAgencyCode&#x27;)
        return sample

    # As an agency user, I want to ensure that deleted FSRS records are not included in submissions.
    def filter_deleted_fsrs(self, records: List[Dict]) -&gt; List[Dict]:
        &quot;&quot;&quot;Filter out deleted FSRS records from submissions.&quot;&quot;&quot;
        filtered = [r for r in records if not r.get(&#x27;is_deleted&#x27;, False)]
        logger.info(f&quot;Filtered {len(records) - len(filtered)} deleted FSRS records.&quot;)
        return filtered

    # As a website user, I want to see updated financial assistance data daily.
    def load_daily_fa_data(self):
        &quot;&quot;&quot;Simulate daily load of financial assistance data.&quot;&quot;&quot;
        today = datetime.date.today().isoformat()
        with self.get_connection() as conn:
            conn.execute(&quot;&quot;&quot;
                INSERT INTO historical_fabs (record_data, loaded_at)
                VALUES (?, ?)
            &quot;&quot;&quot;, (json.dumps({&#x27;date&#x27;: today, &#x27;data&#x27;: &#x27;updated_fa&#x27;}), today))
            conn.commit()
        logger.info(f&quot;Loaded daily FA data for {today}.&quot;)

    # As a user, I want the publish button in FABS to deactivate after I click it while the derivations are happening.
    def simulate_publish_with_derivations(self, submission_id: int):
        &quot;&quot;&quot;Simulate publish with derivations; button deactivated during process.&quot;&quot;&quot;
        self.update_submission_on_status_change(submission_id, SubmissionStatus.VALIDATING.value)
        # Simulate derivation time
        import time
        time.sleep(2)  # Derivations happening
        logger.info(f&quot;Derivations complete for {submission_id}; button reactivates.&quot;)
        self.publish_submission(submission_id)

    # As a Developer, I want to ensure that attempts to correct or delete non-existent records don&#x27;t create new published data.
    def safe_delete_or_correct(self, record_id: int, action: str = &#x27;delete&#x27;) -&gt; bool:
        &quot;&quot;&quot;Safely delete or correct non-existent records without creating new data.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT id FROM historical_fabs WHERE id = ?&quot;, (record_id,))
            if not cursor.fetchone():
                logger.warning(f&quot;Non-existent record {record_id}; {action} ignored.&quot;)
                return False
            if action == &#x27;delete&#x27;:
                conn.execute(&quot;DELETE FROM historical_fabs WHERE id = ?&quot;, (record_id,))
            elif action == &#x27;correct&#x27;:
                # Simulate correction
                conn.execute(&quot;UPDATE historical_fabs SET record_data = ? WHERE id = ?&quot;, (json.dumps({&#x27;corrected&#x27;: True}), record_id))
            conn.commit()
            logger.info(f&quot;{action.capitalize()}d record {record_id}.&quot;)
            return True

    # As an Owner, I want to reset the environment to only take Staging MAX permissions.
    def reset_environment_permissions(self, env: str = &#x27;staging&#x27;):
        &quot;&quot;&quot;Reset permissions to Staging MAX only.&quot;&quot;&quot;
        if env == &#x27;staging&#x27;:
            os.environ[&#x27;PERMISSIONS&#x27;] = &#x27;STAGING_MAX_ONLY&#x27;
            logger.info(&quot;Environment reset to Staging MAX permissions; FABS testers access revoked.&quot;)
        else:
            logger.warning(&quot;Permission reset only for staging.&quot;)

    # As a user, I want the flexfields in my submission file to appear in the warning and error files when the only error is a missing required element.
    def generate_error_files_with_flexfields(self, submission_id: int, errors: List[Dict], flexfields: Dict):
        &quot;&quot;&quot;Include flexfields in error/warning files for missing required elements.&quot;&quot;&quot;
        error_report = {
            &#x27;submission_id&#x27;: submission_id,
            &#x27;errors&#x27;: errors,
            &#x27;flexfields&#x27;: flexfields  # Include even on missing required
        }
        logger.info(f&quot;Generated error file with flexfields: {json.dumps(error_report)}&quot;)
        return error_report

    # As a user, I want to have accurate and complete data related to PPoPCode and PPoPCongressionalDistrict.
    def derive_pp_op_data(self, record: Dict) -&gt; Dict:
        &quot;&quot;&quot;Derive accurate PPoPCode and PPoPCongressionalDistrict.&quot;&quot;&quot;
        # Reasonable derivation logic
        ppop_code = record.get(&#x27;PPoPZIP&#x27;, &#x27;00000&#x27;)
        congressional_district = f&quot;CD-{ppop_code[:2]}&quot; if ppop_code else &quot;Unknown&quot;
        record[&#x27;derived_PPoPCode&#x27;] = ppop_code
        record[&#x27;derived_PPoPCongressionalDistrict&#x27;] = congressional_district
        logger.info(f&quot;Derived PPoP data: {ppop_code} -&gt; {congressional_district}&quot;)
        return record

    # As an agency user, I want the FABS validation rules to accept zero and blank for loan records.
    def validate_loan_record(self, record: Dict, is_loan: bool = True) -&gt; bool:
        &quot;&quot;&quot;Accept zero/blank for loans in FABS rules.&quot;&quot;&quot;
        if is_loan:
            fields = [&#x27;Amount&#x27;, &#x27;Obligation&#x27;]
            for field in fields:
                value = record.get(field)
                if value in (0, &#x27;&#x27;, None):
                    record[field] = value  # Accept without error
                    continue
        return True  # Simplified

    # As an agency user, I want FABS deployed into production.
    # Simulated deployment log.
    def deploy_fabs_to_production(self):
        logger.info(&quot;FABS deployed to production for Financial Assistance data submission.&quot;)

    # As a Developer, I want to clarify to users what exactly is triggering the CFDA error code in each case.
    def get_cfda_error_details(self, record: Dict) -&gt; str:
        &quot;&quot;&quot;Provide detailed CFDA error explanation.&quot;&quot;&quot;
        if not record.get(&#x27;CFDA&#x27;):
            return &quot;CFDA error: Missing required CFDA code. Must be a valid 2-digit program identifier.&quot;
        elif len(record[&#x27;CFDA&#x27;]) != 2:
            return &quot;CFDA error: Invalid length. CFDA must be exactly 2 characters.&quot;
        return &quot;CFDA valid.&quot;

    # As an agency user, I want to be confident that the data coming from SAM is complete.
    def validate_sam_data(self, sam_data: Dict) -&gt; bool:
        &quot;&quot;&quot;Validate completeness of SAM data.&quot;&quot;&quot;
        required_fields = [&#x27;DUNS&#x27;, &#x27;LegalName&#x27;, &#x27;Address&#x27;]
        complete = all(sam_data.get(field) for field in required_fields)
        if not complete:
            logger.warning(&quot;SAM data incomplete.&quot;)
        else:
            logger.info(&quot;SAM data complete.&quot;)
        return complete

    # As a Developer, I want my domain models to be indexed properly.
    # Simulated with DB indexing.
    def create_indexes(self):
        with self.get_connection() as conn:
            conn.execute(&quot;CREATE INDEX IF NOT EXISTS idx_submissions_status ON submissions(status)&quot;)
            conn.execute(&quot;CREATE INDEX IF NOT EXISTS idx_historical_agency ON historical_fabs(agency_code)&quot;)
            conn.commit()
        logger.info(&quot;Created indexes for faster validation.&quot;)

    # As an agency user, I want the FABS validation rules to accept zero and blank for non-loan records.
    def validate_non_loan_record(self, record: Dict, is_loan: bool = False) -&gt; bool:
        &quot;&quot;&quot;Accept zero/blank for non-loans.&quot;&quot;&quot;
        if not is_loan:
            fields = [&#x27;Amount&#x27;, &#x27;Obligation&#x27;]
            for field in fields:
                value = record.get(field)
                if value in (0, &#x27;&#x27;, None):
                    record[field] = value  # Accept
                    continue
        return True

    # As a broker team member, I want to make some updates to the SQL codes for clarity.
    # Example clearer SQL in methods above.

    # As an agency user, I want to have all derived data elements derived properly.
    def derive_all_fields(self, record: Dict) -&gt; Dict:
        &quot;&quot;&quot;Derive all necessary fields.&quot;&quot;&quot;
        record = self.derive_pp_op_data(record)
        # Add more derivations
        record[&#x27;derived_AgencyName&#x27;] = f&quot;Agency {record.get(&#x27;AgencyCode&#x27;, &#x27;Unknown&#x27;)}&quot;
        logger.info(&quot;All fields derived properly.&quot;)
        return record

    # As a broker team member, I want to add the 00***** and 00FORGN PPoPCode cases to the derivation logic.
    def derive_pp_op_special_cases(self, ppop_zip: str) -&gt; str:
        &quot;&quot;&quot;Handle special PPoPCode cases.&quot;&quot;&quot;
        if ppop_zip.startswith(&#x27;00&#x27;) and len(ppop_zip) == 5:
            return &#x27;00DOM&#x27;  # Domestic
        elif ppop_zip == &#x27;00FORGN&#x27;:
            return &#x27;00FORGN&#x27;
        return ppop_zip

    # As a data user, I want to see the office names derived from office codes.
    def derive_office_name(self, office_code: str) -&gt; str:
        &quot;&quot;&quot;Derive office name from code.&quot;&quot;&quot;
        office_map = {&#x27;001&#x27;: &#x27;Office of Finance&#x27;, &#x27;002&#x27;: &#x27;Procurement Office&#x27;}
        return office_map.get(office_code, &#x27;Unknown Office&#x27;)

    # As a broker user, I want the historical FABS loader to derive fields.
    def load_historical_fabs_with_derivations(self, historical_data: List[Dict]):
        &quot;&quot;&quot;Load historical FABS with derivations for correct agency codes.&quot;&quot;&quot;
        for data in historical_data:
            data = self.derive_all_fields(data)
            with self.get_connection() as conn:
                conn.execute(&quot;&quot;&quot;
                    INSERT INTO historical_fabs (record_data, agency_code)
                    VALUES (?, ?)
                &quot;&quot;&quot;, (json.dumps(data), data.get(&#x27;AgencyCode&#x27;)))
            logger.info(f&quot;Loaded historical FABS with derivations for {data.get(&#x27;AgencyCode&#x27;)}&quot;)

    # As a Developer, I want the data loaded from historical FABS to include the FREC derivations.
    def load_historical_with_frec(self, data: List[Dict]):
        &quot;&quot;&quot;Load with FREC derivations.&quot;&quot;&quot;
        for record in data:
            frec = self.derive_frec(record)
            record[&#x27;FREC&#x27;] = frec
            with self.get_connection() as conn:
                conn.execute(&quot;&quot;&quot;
                    INSERT INTO historical_fabs (record_data, frec_derivations)
                    VALUES (?, ?)
                &quot;&quot;&quot;, (json.dumps(record), json.dumps({&#x27;FREC&#x27;: frec})))
        logger.info(&quot;Historical FABS loaded with FREC derivations.&quot;)

    def derive_frec(self, record: Dict) -&gt; str:
        &quot;&quot;&quot;Derive FREC.&quot;&quot;&quot;
        return f&quot;FREC-{record.get(&#x27;AgencyCode&#x27;, &#x27;000&#x27;)}&quot;

    # As a user, I don&#x27;t want to see NASA grants displayed as contracts.
    def classify_award_type(self, record: Dict) -&gt; str:
        &quot;&quot;&quot;Ensure NASA grants not shown as contracts.&quot;&quot;&quot;
        agency = record.get(&#x27;AgencyCode&#x27;, &#x27;&#x27;)
        if &#x27;NASA&#x27; in agency and record.get(&#x27;AwardType&#x27;) == &#x27;Grant&#x27;:
            return &#x27;Grant&#x27;
        return record.get(&#x27;AwardType&#x27;, &#x27;Unknown&#x27;)

    # As a user, I want the DUNS validations to accept records whose ActionTypes are B, C, or D and the DUNS is registered in SAM.
    def validate_duns_for_action_types(self, record: Dict, sam_registered: bool = True) -&gt; bool:
        &quot;&quot;&quot;Accept expired DUNS if registered and action type B,C,D.&quot;&quot;&quot;
        action_type = record.get(&#x27;ActionType&#x27;)
        duns = record.get(&#x27;DUNS&#x27;)
        if action_type in [&#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;] and sam_registered and duns:
            # Even if expired, accept if after initial reg date
            action_date = record.get(&#x27;ActionDate&#x27;)
            if action_date and datetime.datetime.strptime(action_date, &#x27;%Y-%m-%d&#x27;) &gt; datetime.datetime(2000, 1, 1):
                return True
        return False

    # As a broker team member, I want to derive FundingAgencyCode.
    def derive_funding_agency_code(self, record: Dict) -&gt; str:
        &quot;&quot;&quot;Derive FundingAgencyCode for data quality.&quot;&quot;&quot;
        code = record.get(&#x27;AwardingAgencyCode&#x27;, &#x27;000&#x27;)  # Fallback
        record[&#x27;FundingAgencyCode&#x27;] = code
        logger.info(f&quot;Derived FundingAgencyCode: {code}&quot;)
        return code

    # As an agency user, I want the maximum length allowed for LegalEntityAddressLine3 to match Schema v1.1.
    def validate_address_line3(self, address: str, max_len: int = 100) -&gt; bool:  # v1.1 max len example
        &quot;&quot;&quot;Validate LegalEntityAddressLine3 length.&quot;&quot;&quot;
        return len(address) &lt;= max_len

    # As an agency user, I want to use the schema v1.1 headers in my FABS file.
    def get_v1_1_headers(self) -&gt; List[str]:
        &quot;&quot;&quot;Return schema v1.1 headers.&quot;&quot;&quot;
        return [&#x27;ActionDate&#x27;, &#x27;UniqueAwardID&#x27;, &#x27;AwardAmount&#x27;, &#x27;LegalEntityAddressLine3&#x27;]  # Example

    # As a agency user, I want to map the FederalActionObligation properly to the Atom Feed.
    def map_to_atom_feed(self, obligation: float) -&gt; Dict:
        &quot;&quot;&quot;Map FederalActionObligation to Atom Feed.&quot;&quot;&quot;
        return {&#x27;atom:obligation&#x27;: str(obligation), &#x27;feed_type&#x27;: &#x27;Atom&#x27;}

    # As a Broker user, I want to have PPoPZIP+4 work the same as the Legal Entity ZIP validations.
    def validate_pp_op_zip_plus4(self, zip_code: str) -&gt; bool:
        &quot;&quot;&quot;Validate PPoPZIP+4 same as LegalEntity ZIP.&quot;&quot;&quot;
        import re
        pattern = r&#x27;^\d{5}(-\d{4})?$&#x27;
        return bool(re.match(pattern, zip_code))

    # As a FABS user, I want to link the SAMPLE FILE on the &quot;What you want to submit&quot; dialog to point to the correct file.
    def get_sample_file_link(self) -&gt; str:
        &quot;&quot;&quot;Return link to correct sample file.&quot;&quot;&quot;
        return &quot;https://usasspending.gov/sample_fabs_v1.1.csv&quot;  # Simulated

    # As an Agency user, I want FPDS data to be up-to-date daily.
    def load_daily_fpds(self):
        &quot;&quot;&quot;Simulate daily FPDS load.&quot;&quot;&quot;
        today = datetime.date.today().isoformat()
        logger.info(f&quot;Loaded daily FPDS data for {today}.&quot;)

    # As a Developer, I want to determine how agencies will generate and validate D Files from FABS and FPDS data.
    def generate_and_validate_d_file(self, fabs: Dict, fpds: Dict) -&gt; Dict:
        &quot;&quot;&quot;Generate and validate D file.&quot;&quot;&quot;
        d_file = self.generate_d_file(fabs, fpds)
        validation = self.validate_loan_record(json.loads(d_file))  # Example
        return {&#x27;d_file&#x27;: d_file, &#x27;valid&#x27;: validation}

    # As a user, I want to generate and validate D Files from FABS and FPDS data.
    # See above method.

    # As an Agency user, I want the header information box to show updated date AND time.
    def get_header_info(self, submission_id: int) -&gt; str:
        &quot;&quot;&quot;Get updated date and time for header.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT updated_at FROM submissions WHERE id = ?&quot;, (submission_id,))
            row = cursor.fetchone()
            if row:
                dt = datetime.datetime.fromisoformat(row[0])
                return dt.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)
        return &quot;Unknown&quot;

    # As an Agency user, I want to receive a more helpful file-level error when I upload a file with the wrong extension.
    def validate_file_extension(self, filename: str) -&gt; str:
        &quot;&quot;&quot;Provide helpful error for wrong extension.&quot;&quot;&quot;
        if not filename.endswith(&#x27;.csv&#x27;):
            return &quot;Error: File must be CSV (.csv). Please check extension and try again.&quot;
        return &quot;Valid file.&quot;

    # As a tester, I want to have access to test features in environments other than Staging.
    def enable_test_features(self, env: str):
        &quot;&quot;&quot;Enable test features in non-staging env.&quot;&quot;&quot;
        if env != &#x27;staging&#x27;:
            os.environ[&#x27;TEST_MODE&#x27;] = &#x27;enabled&#x27;
            logger.info(f&quot;Test features enabled in {env}.&quot;)

    # As a FABS user, I want to submission errors to accurately represent FABS errors.
    def get_submission_errors(self, submission_id: int) -&gt; List[str]:
        &quot;&quot;&quot;Retrieve accurate FABS errors.&quot;&quot;&quot;
        errors = []
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;&quot;&quot;
                SELECT error_message FROM validations
                WHERE submission_id = ? AND is_valid = FALSE
            &quot;&quot;&quot;, (submission_id,))
            for row in cursor:
                errors.append(row[0])
        return errors

    # As a FABS user, I want the frontend URLs to more accurately reflect the page I&#x27;m accessing.
    # Simulated URL mapping.
    def get_fabs_url(self, page: str) -&gt; str:
        &quot;&quot;&quot;Accurate URL for page.&quot;&quot;&quot;
        base = &quot;https://broker.usaspending.gov/fabs&quot;
        return f&quot;{base}/{page.lower().replace(&#x27; &#x27;, &#x27;_&#x27;)}&quot;

    # As an Agency user, I want all historical Financial Assistance data loaded for FABS go-live.
    def load_all_historical_fa(self):
        &quot;&quot;&quot;Load all historical FA data.&quot;&quot;&quot;
        # Simulate
        historical = [{&#x27;id&#x27;: i, &#x27;data&#x27;: f&#x27;historical_{i}&#x27;} for i in range(1000)]
        self.load_historical_fabs_with_derivations(historical)
        logger.info(&quot;All historical FA data loaded for FABS go-live.&quot;)

    # As a Developer, I want the historical FPDS data loader to include both extracted historical data and FPDS feed data.
    def load_historical_fpds(self, extracted_data: List[Dict], feed_data: List[Dict]):
        &quot;&quot;&quot;Load historical FPDS from extracted and feed.&quot;&quot;&quot;
        all_data = extracted_data + feed_data
        for data in all_data:
            logger.info(f&quot;Loaded FPDS historical: {data}&quot;)
        logger.info(&quot;Historical FPDS loaded from extracted and feed.&quot;)

    # As an Agency user, I want historical FPDS data loaded.
    # See above.

    # As an Agency user, I want to accurately see who created a submission.
    def get_submission_creator(self, submission_id: int) -&gt; str:
        &quot;&quot;&quot;Get accurate creator info.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT user_id FROM submissions WHERE id = ?&quot;, (submission_id,))
            row = cursor.fetchone()
            if row:
                return row[0]
        return &quot;Unknown&quot;

    # As an agency user, I want to get File F in the correct format.
    def generate_file_f(self, data: Dict) -&gt; str:
        &quot;&quot;&quot;Generate File F in correct format.&quot;&quot;&quot;
        return json.dumps(data, indent=2)  # Simplified

    # As an Agency user, I want to better understand my file-level errors.
    def explain_file_errors(self, errors: List[str]) -&gt; str:
        &quot;&quot;&quot;Provide better explanations for file errors.&quot;&quot;&quot;
        explanations = [f&quot;Error: {e}. Fix by checking data format.&quot; for e in errors]
        return &quot;; &quot;.join(explanations)

    # As a Developer, I want to provide FABS groups that function under the FREC paradigm.
    def create_fabs_groups_frec(self, groups: List[Dict]):
        &quot;&quot;&quot;Create FABS groups with FREC.&quot;&quot;&quot;
        for group in groups:
            group[&#x27;FREC_Group&#x27;] = self.derive_frec(group)
        logger.info(&quot;FABS groups created under FREC paradigm.&quot;)

    # As a tester, I want to ensure that FABS is deriving fields properly through a robust test file plus a follow up check.
    def test_derivations(self, test_file: Dict):
        &quot;&quot;&quot;Test derivations with robust file.&quot;&quot;&quot;
        derived = self.derive_all_fields(test_file)
        # Follow-up check
        assert derived.get(&#x27;derived_PPoPCode&#x27;) == test_file.get(&#x27;PPoPZIP&#x27;)
        logger.info(&quot;Derivation test passed.&quot;)
        return True

    # As an owner, I only want zero-padded fields.
    def pad_fields_with_zeros(self, record: Dict, fields: List[str]):
        &quot;&quot;&quot;Ensure zero-padded fields.&quot;&quot;&quot;
        for field in fields:
            value = str(record.get(field, &#x27;&#x27;))
            if value.isdigit():
                record[field] = value.zfill(10)  # Example padding
        logger.info(&quot;Fields zero-padded.&quot;)

    # As a Broker user, I want to submit records for individual recipients without receiving a DUNS error.
    def submit_individual_recipient(self, record: Dict):
        &quot;&quot;&quot;Allow submission without DUNS error for individuals.&quot;&quot;&quot;
        if not record.get(&#x27;DUNS&#x27;) and record.get(&#x27;RecipientType&#x27;) == &#x27;Individual&#x27;:
            record[&#x27;DUNS_Validated&#x27;] = True  # Bypass error
        logger.info(f&quot;Submitted individual recipient: {record.get(&#x27;UniqueID&#x27;)}&quot;)

    # As a user, I want more information about how many rows will be published prior to deciding whether to publish.
    def get_publish_preview(self, submission_id: int) -&gt; Dict:
        &quot;&quot;&quot;Preview rows to be published.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT COUNT(*) FROM submissions WHERE id = ?&quot;, (submission_id,))
            count = cursor.fetchone()[0]
            return {&#x27;rows_to_publish&#x27;: count, &#x27;estimated_size&#x27;: f&quot;{count} records&quot;}
        return {&#x27;rows_to_publish&#x27;: 0}

    # As a Developer, I want to prevent duplicate transactions from being published and deal with the time gap between validation and the publishing decision.
    def publish_with_duplicate_check(self, submission_id: int, validation_time: datetime):
        &quot;&quot;&quot;Prevent duplicates with time gap handling.&quot;&quot;&quot;
        current_time = datetime.datetime.now()
        if (current_time - validation_time).seconds &gt; 300:  # 5 min gap
            logger.warning(&quot;Time gap too large; re-validate.&quot;)
            return False
        unique_hash = hashlib.md5(f&quot;{submission_id}_{validation_time}&quot;.encode()).hexdigest()
        if unique_hash in self.cache:
            logger.warning(&quot;Duplicate transaction prevented.&quot;)
            return False
        self.cache[unique_hash] = True
        return self.publish_submission(submission_id)

    # As a FABS user, I want to submit a citywide as a PPoPZIP and pass validations.
    def validate_citywide_pp_op_zip(self, zip_code: str) -&gt; bool:
        &quot;&quot;&quot;Allow citywide ZIP submissions.&quot;&quot;&quot;
        if zip_code == &#x27;CITYWIDE&#x27;:
            return True
        return self.validate_pp_op_zip_plus4(zip_code)

    # As a Broker user, I want to have updated error codes that accurately reflect the logic.
    def generate_updated_error_codes(self, record: Dict) -&gt; List[str]:
        &quot;&quot;&quot;Updated error codes with details.&quot;&quot;&quot;
        errors = []
        if not record.get(&#x27;CFDA&#x27;):
            errors.append(&quot;ERR001: Missing CFDA - Required for all awards.&quot;)
        return errors

    # As an agency user, I want to leave off the last 4 digits of the ZIP without an error.
    def validate_zip_without_plus4(self, zip_code: str) -&gt; bool:
        &quot;&quot;&quot;Accept 5-digit ZIP without +4.&quot;&quot;&quot;
        if len(zip_code) == 5 and zip_code.isdigit():
            return True
        return self.validate_pp_op_zip_plus4(zip_code)

    # As a FABS user, I want to make sure the historical data includes all necessary columns.
    def validate_historical_columns(self, data: List[Dict]) -&gt; bool:
        &quot;&quot;&quot;Check historical data has necessary columns.&quot;&quot;&quot;
        required = [&#x27;ActionDate&#x27;, &#x27;UniqueAwardID&#x27;]
        for record in data:
            if not all(record.get(col) for col in required):
                logger.warning(&quot;Missing columns in historical data.&quot;)
                return False
        logger.info(&quot;Historical data columns validated.&quot;)
        return True

    # As a data user, I want to access two additional fields from the FPDS data pull.
    def pull_fpds_with_extra_fields(self) -&gt; Dict:
        &quot;&quot;&quot;Pull FPDS with two extra fields.&quot;&quot;&quot;
        return {
            &#x27;base_data&#x27;: &#x27;fpds_base&#x27;,
            &#x27;extra_field1&#x27;: &#x27;ContractType&#x27;,
            &#x27;extra_field2&#x27;: &#x27;ObligatedAmount&#x27;
        }

    # As a FABS user, I want additional helpful info in the submission dashboard.
    def get_submission_dashboard_info(self, user_id: str) -&gt; Dict:
        &quot;&quot;&quot;Helpful dashboard info.&quot;&quot;&quot;
        subs = []
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT * FROM submissions WHERE user_id = ?&quot;, (user_id,))
            for row in cursor:
                subs.append({
                    &#x27;id&#x27;: row[0],
                    &#x27;status&#x27;: row[3],
                    &#x27;updated&#x27;: row[5],
                    &#x27;rows&#x27;: self.get_publish_preview(row[0])[&#x27;rows_to_publish&#x27;]
                })
        return {&#x27;submissions&#x27;: subs, &#x27;total&#x27;: len(subs), &#x27;tips&#x27;: &#x27;Check validations before publish.&#x27;}

    # As a FABS user, I want to download the uploaded FABS file.
    def download_uploaded_file(self, submission_id: int) -&gt; Optional[str]:
        &quot;&quot;&quot;Download uploaded file content.&quot;&quot;&quot;
        return self.get_raw_fabs_file(&#x27;agency&#x27;, submission_id)

    # As a Developer I want to quickly access Broker application data.
    def quick_access_broker_data(self, query: str) -&gt; List[Dict]:
        &quot;&quot;&quot;Quick access to data for investigation.&quot;&quot;&quot;
        with self.get_connection() as conn:
            cursor = conn.execute(query)
            return [dict(row) for row in cursor.fetchall()]
        return []

    # As a Developer, I want to determine the best way to load historical FPDS data since 2007.
    def load_historical_fpds_since_2007(self):
        &quot;&quot;&quot;Load FPDS data since 2007.&quot;&quot;&quot;
        start_date = datetime.date(2007, 1, 1)
        # Simulate load
        years = (datetime.date.today() - start_date).days // 365
        logger.info(f&quot;Loaded historical FPDS data since 2007 ({years} years).&quot;)

    # As a FABS user, I want the language on FABS pages to be appropriate for me.
    # Simulated with user-friendly messages.
    def get_user_friendly_message(self, context: str) -&gt; str:
        &quot;&quot;&quot;Appropriate language.&quot;&quot;&quot;
        messages = {
            &#x27;validation&#x27;: &quot;Your file has been validated. Review errors and try again.&quot;,
            &#x27;publish&#x27;: &quot;Publishing your submission. This may take a moment.&quot;
        }
        return messages.get(context, &quot;Welcome to FABS.&quot;)

    # As a FABS user, I do not want DABS banner messages and vice versa.
    def get_app_specific_banner(self, app: str) -&gt; str:
        &quot;&quot;&quot;App-specific banners.&quot;&quot;&quot;
        if app == &#x27;fabs&#x27;:
            return &quot;FABS: Submit Financial Assistance Data&quot;
        return &quot;DABS: Submit Disaster Assistance Data&quot;

    # As a FABS user, I want to have read-only access to DABS.
    def set_read_only_access(self, user_id: str, app: str = &#x27;dabs&#x27;):
        &quot;&quot;&quot;Set read-only for DABS.&quot;&quot;&quot;
        logger.info(f&quot;Set read-only access for user {user_id} to {app}.&quot;)

    # As a FABS user, I want to have my validations run in a reasonable amount of time.
    # Handled by indexing.

    # As a FABS user, I want to see correct status labels on the Submission Dashboard.
    def get_status_label(self, status: str) -&gt; str:
        &quot;&quot;&quot;Correct labels.&quot;&quot;&quot;
        labels = {
            &#x27;draft&#x27;: &#x27;Draft - Ready to Edit&#x27;,
            &#x27;published&#x27;: &#x27;Published - Live&#x27;,
            &#x27;error&#x27;: &#x27;Error - Review Issues&#x27;
        }
        return labels.get(status, &#x27;Unknown&#x27;)

    # As an agency user, I want to know when the submission periods start and end.
    def get_submission_periods(self) -&gt; List[Dict]:
        &quot;&quot;&quot;Submission periods.&quot;&quot;&quot;
        return [
            {&#x27;start&#x27;: &#x27;2023-10-01&#x27;, &#x27;end&#x27;: &#x27;2023-12-31&#x27;, &#x27;type&#x27;: &#x27;Quarterly&#x27;}
        ]

    # As an agency user, I want a landing page to navigate to either FABS or DABS pages.
    # Simulated navigation.
    def navigate_to_app(self, app: str) -&gt; str:
        &quot;&quot;&quot;Navigate to FABS or DABS.&quot;&quot;&quot;
        return f&quot;Navigating to {app.upper()} landing page.&quot;

    # As an agency user, I want to submit my data elements surrounded by quotation marks.
    def process_quoted_data(self, data: List[str]) -&gt; List[str]:
        &quot;&quot;&quot;Handle quoted data to preserve zeros.&quot;&quot;&quot;
        processed = [f&#x27;&quot;{d}&quot;&#x27; for d in data]
        return processed

    # As a Broker user, I want to Upload and Validate the error message to have accurate text.
    def upload_and_validate_with_accurate_errors(self, file_content: str, filename: str):
        &quot;&quot;&quot;Upload and validate with accurate error text.&quot;&quot;&quot;
        ext_error = self.validate_file_extension(filename)
        if ext_error != &quot;Valid file.&quot;:
            raise ValueError(ext_error)
        # Simulate validation
        errors = self.get_cfda_error_details({&#x27;CFDA&#x27;: &#x27;&#x27;})
        logger.info(f&quot;Validation errors: {errors}&quot;)

    # As a Broker user, I want the D1 file generation to be synced with the FPDS data load.
    def generate_d1_synced_with_fpds(self, fpds_loaded: bool = True) -&gt; str:
        &quot;&quot;&quot;Generate D1 only if FPDS updated.&quot;&quot;&quot;
        if not fpds_loaded:
            logger.info(&quot;No FPDS update; skipping D1 generation.&quot;)
            return &quot;&quot;
        return self.generate_d_file({}, {})  # Synced

    # As a Website user, I want to access published FABS files.
    def access_published_fabs_files(self) -&gt; List[str]:
        &quot;&quot;&quot;Access list of published files.&quot;&quot;&quot;
        files = []
        with self.get_connection() as conn:
            cursor = conn.execute(&quot;SELECT file_content FROM submissions WHERE status = ?&quot;, (SubmissionStatus.PUBLISHED.value,))
            for row in cursor:
                files.append(row[0])
        return files

    # As an owner, I want to be sure that USAspending only send grant records to my system.
    def filter_only_grants(self, records: List[Dict]) -&gt; List[Dict]:
        &quot;&quot;&quot;Filter to only grant records.&quot;&quot;&quot;
        grants = [r for r in records if r.get(&#x27;AwardType&#x27;) == &#x27;Grant&#x27;]
        logger.info(f&quot;Filtered to {len(grants)} grant records only.&quot;)
        return grants

    # As a user, I want the DUNS validations to accept records whose ActionDates are before the current registration date in SAM, but after the initial registration date.
    # Already partially in validate_duns_for_action_types.

# Example usage to make it functional
if __name__ == &quot;__main__&quot;:
    broker = BrokerSystem(&quot;broker.db&quot;)
    
    # Simulate some operations
    broker.process_2017_12_19_deletions([{&#x27;date&#x27;: &#x27;2017-12-19&#x27;, &#x27;id&#x27;: 1}])
    broker.add_gtas_window(&#x27;2023-10-01&#x27;, &#x27;2023-10-15&#x27;)
    sample = broker.generate_sample_file()
    print(json.dumps(sample))
    
    # Add a submission
    with broker.get_connection() as conn:
        conn.execute(&quot;INSERT INTO submissions (user_id, file_content, status) VALUES (?, ?, ?)&quot;,
                     (&#x27;test_user&#x27;, json.dumps({&#x27;data&#x27;: &#x27;test&#x27;}), SubmissionStatus.DRAFT.value))
        submission_id = conn.lastrowid
        conn.commit()
    
    broker.publish_submission(submission_id)
    broker.simulate_publish_with_derivations(submission_id)</code></pre>
        </details>
    </div>
</body>
</html>
    